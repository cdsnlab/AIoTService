{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Connect to Google Drive"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/gdrive')\n",
    "gdrive_root = '/gdrive/My Drive'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Import modules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "!pip install pyngrok\n",
    "# import TensorBoardColab\n",
    "!pip install -U tensorboardcolab\n",
    "from tensorboardcolab import TensorBoardColab\n",
    "\n",
    "torch.manual_seed(470)\n",
    "torch.cuda.manual_seed(470)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Configure the experiments"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# training & optimization hyper-parameters\n",
    "max_epoch = 10\n",
    "learning_rate = 0.0001\n",
    "batch_size = 200\n",
    "device = 'cuda'\n",
    "\n",
    "# model hyper-parameters\n",
    "input_dim = 784 # 28x28=784\n",
    "hidden_dim = 512\n",
    "output_dim = 10 \n",
    "\n",
    "# initialize tensorboard for visualization\n",
    "# Note : click the Tensorboard link to see the visualization of training/testing results\n",
    "# tbc = TensorBoardColab()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Construct data pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_dir = os.path.join(gdrive_root, 'my_data')\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_dataset = MNIST(data_dir, train=True, download=True, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "test_dataset = MNIST(data_dir, train=False, download=True, transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Construct a neural network builder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class MyClassifier(nn.Module):\n",
    "  def __init__(self, input_dim=784, hidden_dim=512, output_dim=10):\n",
    "    super(MyClassifier, self).__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Linear(input_dim, hidden_dim),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(hidden_dim, hidden_dim),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(hidden_dim, hidden_dim),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(hidden_dim, output_dim),\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    batch_size = x.size(0)\n",
    "    x = x.view(batch_size, -1)\n",
    "    outputs = self.layers(x)\n",
    "    return outputs"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
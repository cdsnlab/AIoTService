{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Import"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(torch.__version__)\n",
    "from torch import cuda\n",
    "print(cuda.get_device_name(cuda.current_device()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Load data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 30\n",
    "\n",
    "train_kwargs = {'batch_size': 128, 'shuffle': True}\n",
    "valid_kwargs = {'batch_size': 128, 'shuffle': False}\n",
    "test_kwargs = {'batch_size': 128, 'shuffle': False}\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform=transforms.Compose([\n",
    "        # Pad images with 0s\n",
    "        transforms.Pad((0,4,4,0), fill=0, padding_mode='constant'),\n",
    "    \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        ])\n",
    "dataset_full = datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transform)\n",
    "valid_size = 5000\n",
    "train_size = len(dataset_full) - 5000\n",
    "dataset_train, dataset_valid = torch.utils.data.random_split(dataset_full, [train_size, valid_size])\n",
    "\n",
    "dataset_test = datasets.MNIST('../data', train=False,\n",
    "                   transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train,**train_kwargs)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset_valid,**valid_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, **test_kwargs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print()\n",
    "print(\"Image Shape: {}\".format(dataset_train[0][0].shape))\n",
    "print()\n",
    "print(\"Training Set:   {} samples\".format(len(dataset_train)))\n",
    "print(\"Validation Set:   {} samples\".format(len(dataset_valid)))\n",
    "print(\"Test Set:       {} samples\".format(len(dataset_test)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pdb\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0, len(dataset_train))\n",
    "image = dataset_train[index][0].squeeze()\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(image)\n",
    "print(\"Label of the image is:%d\"%dataset_train[index][1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. LeNet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Pytorch modification From https://www.kaggle.com/usingtc/lenet-with-pytorch\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "        self.conv1 = nn.Conv2d(1, 6, (5,5))\n",
    "        # Layer 2: Convolutional. Output = 10x10x16.\n",
    "        self.conv2 = nn.Conv2d(6, 16, (5,5))\n",
    "        # Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "        self.fc1   = nn.Linear(400, 120)\n",
    "        # Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        # Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "    def forward(self, x):\n",
    "        # Activation. # Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "         # Activation. # Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        # Flatten. Input = 5x5x16. Output = 400.\n",
    "        x = x.flatten(start_dim=1)\n",
    "        # Activation.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Activation.\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import packages\n",
    "\"\"\"\n",
    "import os, glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, random\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "import path, sys, re, time\n",
    "from collections import Counter\n",
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import custom packages\n",
    "\"\"\"\n",
    "from module_.info.testbed_info import activityfiles_new\n",
    "from module_.info.config import config, feature_name\n",
    "from module_.readText import create_episodes, time_correction\n",
    "from module_.featureExtraction import feature_extraction\n",
    "from module_.changePointDetection import change_point_detection\n",
    "# from module_.info.testbed_info import d_files, g_files, c_files, p_files\n",
    "# from module_.info.config import config, feature_name\n",
    "# from module_.readText import create_episodes, time_correction, create_episodes_intra\n",
    "# from module_.featureExtraction import feature_extraction\n",
    "# from module_.changePointDetection import change_point_detection\n",
    "# from module_.evaluation import episode_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load raw files\n",
    "\"\"\"\n",
    "dir_=\"dataset/testbed/npy/seminar/MS\"\n",
    "task_dict={i:[np.load(\"{}/{}\".format(dir_, name)) for name in v] for i, v in enumerate(activityfiles_new.values())}\n",
    "initial_dict={i:k[0] for i, k in enumerate(activityfiles_new.keys())}\n",
    "label_dict={k[0]:k for k in activityfiles_new.keys()}\n",
    "\n",
    "episodes, trs, tags = create_episodes(task_dict, initial_dict)\n",
    "episodes=[time_correction(eps, trs[i]) for i, eps in enumerate(episodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "creating folders\n",
    "\"\"\"\n",
    "\n",
    "dataset='testbed'\n",
    "preprocess='MS'\n",
    "metric='RuLSIF'\n",
    "\n",
    "for i, eps in enumerate(episodes):\n",
    "\n",
    "    pairname=\"{}-{}\".format(label_dict[tags[i][0]], label_dict[tags[i][2]])\n",
    "    actpairfolder=\"./outputs/{}/{}/{}\".format(dataset, preprocess, pairname)\n",
    "    epsfolder=\"{}/{}_{}_{}\".format(actpairfolder, i, tags[i], trs[i])\n",
    "    metricfolder=\"{}/CPD/{}\".format(epsfolder, metric)\n",
    "    \n",
    "    if not os.path.exists(actpairfolder):\n",
    "        os.mkdir(actpairfolder)\n",
    "    if not os.path.exists(epsfolder):\n",
    "        os.mkdir(epsfolder)\n",
    "    if not os.path.exists(\"{}/event\".format(epsfolder)):\n",
    "        os.mkdir(\"{}/event\".format(epsfolder))\n",
    "    if not os.path.exists(\"{}/feature\".format(epsfolder)):\n",
    "        os.mkdir(\"{}/feature\".format(epsfolder))\n",
    "    if not os.path.exists(\"{}/CPD\".format(epsfolder)):\n",
    "        os.mkdir(\"{}/CPD\".format(epsfolder))\n",
    "    if not os.path.exists(metricfolder):\n",
    "        os.mkdir(metricfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset='testbed'\n",
    "preprocess='MS'\n",
    "metric='RuLSIF'\n",
    "\n",
    "for i, eps in enumerate(episodes):\n",
    "    print(i, tags[i])\n",
    "    pairname=\"{}-{}\".format(label_dict[tags[i][0]], label_dict[tags[i][2]])\n",
    "    actpairfolder=\"./outputs/{}/{}/{}\".format(dataset, preprocess, pairname)\n",
    "    epsfolder=\"{}/{}_{}_{}\".format(actpairfolder, i, tags[i], trs[i])\n",
    "    metricfolder=\"{}/CPD/{}\".format(epsfolder, metric)\n",
    "\n",
    "    np.save(\"{}/event/eps.npy\".format(epsfolder), eps)\n",
    "\n",
    "    sensor_list=sorted(set(eps[:,0]))\n",
    "    features=feature_extraction(eps, dataset, sensor_list)\n",
    "\n",
    "    np.save(\"{}/feature/feat.npy\".format(epsfolder), features)\n",
    "\n",
    "    scores=change_point_detection(features, metricfolder, data_name=dataset, metric=metric, save=True)\n",
    "    scores=np.array(scores)\n",
    "    scores[scores<0]=0\n",
    "    \n",
    "###\n",
    "    plt.title(\"{}-{}\".format(tags[i], i))\n",
    "    plt.ylabel('score')\n",
    "    plt.xlabel('event')\n",
    "    plt.ylim(0,3)\n",
    "    plt.bar(range(len(eps)), scores)\n",
    "    # plt.plot(positive, np.array(scores)[positive], 'bx', label='peak')\n",
    "    # plt.axhline(y=0.1, linestyle=':', color='r', label='threshold')\n",
    "    plt.axvline(x=trs[i], linestyle=':', color='g', label='transition')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"{}/graph.png\".format(metricfolder))\n",
    "    plt.clf()\n",
    "    \n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save events and features according to Transition/Non-transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='testbed'\n",
    "preprocess='MS'\n",
    "metric='RuLSIF'\n",
    "\n",
    "\n",
    "threshold=60\n",
    "\n",
    "for activitydir in glob.glob(\"./outputs/{}/{}/*\".format(dataset, preprocess)):\n",
    "    pairname=activitydir.split(\"/\")[-1]\n",
    "    leftset=set()\n",
    "    rightset=set()\n",
    "    for epsdir in glob.glob(\"{}/*\".format(activitydir)):\n",
    "        # epsnumber, actinitial, changepoint=epsdir.split(\"_\")\n",
    "        epsnumber, actinitial = epsdir.split(\"_\")\n",
    "        epsnumber=int(epsnumber.split(\"/\")[-1])\n",
    "        leftact, rightact = actinitial[1], actinitial[3]\n",
    "        eps, changepoint=episodes[epsnumber], trs[epsnumber]\n",
    "        features=np.load(\"{}/feature/feat.npy\".format(epsdir))\n",
    "        scores=np.load(\"{}/CPD/{}/scores.npy\".format(epsdir, metric))\n",
    "\n",
    "        Astarttime=float(eps[0,2])\n",
    "        Aendtime=float(eps[changepoint-1,2])\n",
    "\n",
    "        Bstarttime=float(eps[changepoint,2])\n",
    "        Bendtime=float(eps[-1,2])\n",
    "\n",
    "        TASe=np.array([item for item in eps[:changepoint] if float(item[2])<Astarttime+threshold])\n",
    "        TAEe=np.array([item for item in eps[:changepoint] if float(item[2])>Aendtime-threshold])\n",
    "        \n",
    "        TBSe=np.array([item for item in eps[changepoint:] if float(item[2])<Bstarttime+threshold])\n",
    "        TBEe=np.array([item for item in eps[changepoint:] if float(item[2])>Bendtime-threshold])\n",
    "\n",
    "        NAe=np.array([item for item in eps[:changepoint] if Astarttime+threshold<=float(item[2])<=Aendtime-threshold])\n",
    "        NBe=np.array([item for item in eps[changepoint:] if Bstarttime+threshold<=float(item[2])<=Bendtime-threshold])\n",
    "\n",
    "        ####\n",
    "        TASf=features[:TASe.shape[0]]\n",
    "        TASs=scores[:TASe.shape[0]]\n",
    "        assert len(TASf)==len(TASs)\n",
    "\n",
    "        TAEf=features[changepoint-TAEe.shape[0]:changepoint]\n",
    "        TAEs=scores[changepoint-TAEe.shape[0]:changepoint]\n",
    "        assert len(TAEf)==len(TAEs)\n",
    "\n",
    "        TBSf=features[changepoint:changepoint+TBSe.shape[0]]\n",
    "        TBSs=scores[changepoint:changepoint+TBSe.shape[0]]\n",
    "        assert len(TBSf)==len(TBSs)\n",
    "\n",
    "        TBEf=features[len(features)-TBEe.shape[0]:]\n",
    "        TBEs=scores[len(scores)-TBEe.shape[0]:]\n",
    "        assert len(TBEf)==len(TBEs)\n",
    "\n",
    "        NAf=features[len(TASf):changepoint-len(TAEf)]\n",
    "        NAs=scores[len(TASs):changepoint-len(TAEs)]\n",
    "        assert len(NAf)==len(NAs)\n",
    "\n",
    "        NBf=features[changepoint+len(TBSf):len(features)-len(TBEf)]\n",
    "        NBs=scores[changepoint+len(TBSs):len(scores)-len(TBEs)]\n",
    "        assert len(NBf)==len(NBs)\n",
    "\n",
    "        eventdir=\"{}/event\".format(epsdir)\n",
    "        featuredir=\"{}/feature\".format(epsdir)\n",
    "        scoredir=\"{}/CPD/{}/score\".format(epsdir, metric)\n",
    "        if not os.path.exists(scoredir):\n",
    "            os.mkdir(scoredir)\n",
    "\n",
    "        np.save(\"{}/TASe.npy\".format(eventdir), TASe)\n",
    "        np.save(\"{}/TBSe.npy\".format(eventdir), TBSe)\n",
    "        np.save(\"{}/TAEe.npy\".format(eventdir), TAEe)\n",
    "        np.save(\"{}/TBEe.npy\".format(eventdir), TBEe)\n",
    "        np.save(\"{}/NAe.npy\".format(eventdir), NAe)\n",
    "        np.save(\"{}/NBe.npy\".format(eventdir), NBe)\n",
    "\n",
    "        np.save(\"{}/TASf.npy\".format(featuredir), TASf)\n",
    "        np.save(\"{}/TBSf.npy\".format(featuredir), TBSf)\n",
    "        np.save(\"{}/TAEf.npy\".format(featuredir), TAEf)\n",
    "        np.save(\"{}/TBEf.npy\".format(featuredir), TBEf)\n",
    "        np.save(\"{}/NAf.npy\".format(featuredir), NAf)\n",
    "        np.save(\"{}/NBf.npy\".format(featuredir), NBf)\n",
    "\n",
    "        np.save(\"{}/TASs.npy\".format(scoredir), TASs)\n",
    "        np.save(\"{}/TBSs.npy\".format(scoredir), TBSs)\n",
    "        np.save(\"{}/TAEs.npy\".format(scoredir), TAEs)\n",
    "        np.save(\"{}/TBEs.npy\".format(scoredir), TBEs)\n",
    "        np.save(\"{}/NAs.npy\".format(scoredir), NAs)\n",
    "        np.save(\"{}/NBs.npy\".format(scoredir), NBs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name='testbed'\n",
    "preprocess='MS'\n",
    "metric='RuLSIF'\n",
    "\n",
    "threshold=0.1\n",
    "\n",
    "dict_={item:set() for item in ['C','T','G','S']}\n",
    "\n",
    "l=[]\n",
    "\n",
    "# f=open(\"./alarming_TAS.txt\", 'w')\n",
    "alarmlist=[]\n",
    "\n",
    "for activitydir in glob.glob(\"./outputs/{}/{}/*\".format(data_name, preprocess)):\n",
    "    pairname=activitydir.split(\"/\")[-1]\n",
    "    # print(pairname)\n",
    "    for epsdir in glob.glob(\"{}/*\".format(activitydir)):\n",
    "        \n",
    "        epsnumber, actinitial = epsdir.split(\"_\")\n",
    "        epsnumber=int(epsnumber.split(\"/\")[-1])\n",
    "        leftact, leftorder = actinitial[0], actinitial[1]\n",
    "        rightact, rightorder = actinitial[2], actinitial[3]\n",
    "\n",
    "\n",
    "        if leftorder in dict_[leftact]:\n",
    "            continue\n",
    "        dict_[leftact].add(leftorder)\n",
    "        print(epsdir.split(\"_\")[-1])\n",
    "        # print(leftact, leftorder)\n",
    "        # events\n",
    "        # TASe=np.load(\"{}/event/TASe.npy\".format(epsdir))\n",
    "        # TBSe=np.load(\"{}/event/TBSe.npy\".format(epsdir))\n",
    "        # TAEe=np.load(\"{}/event/TAEe.npy\".format(epsdir))\n",
    "        # TBEe=np.load(\"{}/event/TBEe.npy\".format(epsdir))\n",
    "        NAe=np.load(\"{}/event/NAe.npy\".format(epsdir))\n",
    "        # NBe=np.load(\"{}/event/NBe.npy\".format(epsdir))\n",
    "\n",
    "        # features\n",
    "        # TASf=np.load(\"{}/feature/TASf.npy\".format(epsdir))\n",
    "        # TBSf=np.load(\"{}/feature/TBSf.npy\".format(epsdir))\n",
    "        # TAEf=np.load(\"{}/feature/TAEf.npy\".format(epsdir))\n",
    "        # TBEf=np.load(\"{}/feature/TBEf.npy\".format(epsdir))\n",
    "        # NAf=np.load(\"{}/feature/NAf.npy\".format(epsdir))\n",
    "        # NBf=np.load(\"{}/feature/NBf.npy\".format(epsdir))\n",
    "\n",
    "        # scores\n",
    "        scoredir=\"{}/CPD/{}/score\".format(epsdir, metric)\n",
    "        # TASs=np.load(\"{}/TASs.npy\".format(scoredir))\n",
    "        # TBSs=np.load(\"{}/TBSs.npy\".format(scoredir))\n",
    "        # TAEs=np.load(\"{}/TAEs.npy\".format(scoredir))\n",
    "        # TBEs=np.load(\"{}/TBEs.npy\".format(scoredir))\n",
    "        NAs=np.load(\"{}/NAs.npy\".format(scoredir))\n",
    "        # NBs=np.load(\"{}/NBs.npy\".format(scoredir))\n",
    "\n",
    "        # sum_=0\n",
    "        # target=NAs\n",
    "        # for i in range(target.shape[0]-1):\n",
    "        #     sum_+=abs(target[i]-target[i+1])\n",
    "\n",
    "        # print(sum_/target.shape[0])\n",
    "\n",
    "        # print(TASe.shape[0])\n",
    "        targetscores=NAs\n",
    "        # # targetfeatures=NAf\n",
    "        # # targetindices=sorted([(score, idx) for idx, score in enumerate(targetscores)], reverse=True)\n",
    "        targetindices=[(score, idx) for idx, score in enumerate(targetscores) if score>threshold]\n",
    "        \n",
    "        for score, index_ in targetindices:\n",
    "            # f.write(\"{} {} {} {} \\n\".format(pairname, epsdir.split(\"/\")[-1], index_, score))\n",
    "            alarmlist.append([pairname, epsdir.split(\"/\")[-1], index_, score])\n",
    "            # views=np.array([targetfeatures[max(0, index_-1)], targetfeatures[index_], targetfeatures[min(len(targetfeatures)-1, index_+1)]])\n",
    "            # print(np.square(distance_matrix(before[:2], before[:2])), \"test-test\")\n",
    "            # print(np.square(distance_matrix(before[:2], before[1:])), \"test-train\")\n",
    "            # print(np.tril(distance_matrix(before, before)))\n",
    "            # A1A2=np.square(distance_matrix(views[:2], views[:2]))[0,1]\n",
    "            # A1A3=np.square(distance_matrix(views[:2], views[1:]))[0,1]\n",
    "            # A2A3=np.square(distance_matrix(views[:2], views[1:]))[1,1]\n",
    "            # print(A1A2, A1A3, A2A3)\n",
    "            # l.append([score, A1A2, A1A3, A2A3])\n",
    "np.save(\"./alarming_NA.npy\", np.array(alarmlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name='testbed'\n",
    "preprocess='MS'\n",
    "metric='RuLSIF'\n",
    "\n",
    "alarming_=np.load(\"./alarming_NA.npy\")\n",
    "print(alarming_.shape)\n",
    "for item in alarming_:\n",
    "\n",
    "    location=\"./outputs/{}/{}/{}/{}\".format(data_name, preprocess, item[0], item[1])\n",
    "\n",
    "    events_all=np.load(\"{}/event/eps.npy\".format(location))\n",
    "    # features=np.load(\"{}/feature/feat.npy\".format(location))\n",
    "    # scores=np.load(\"{}/CPD/{}/scores.npy\".format(location, metric))\n",
    "\n",
    "    events=np.load(\"{}/event/NAe.npy\".format(location))\n",
    "    features=np.load(\"{}/feature/NAf.npy\".format(location))\n",
    "    scores=np.load(\"{}/CPD/{}/score/NAs.npy\".format(location, metric))\n",
    "\n",
    "    index_=int(item[2])\n",
    "\n",
    "    # offset_idx=len(events)-tae_length\n",
    "    # print(offset_idx)\n",
    "\n",
    "    event=events[max(0, index_-31):index_+2]\n",
    "    offset_t=float(event[0,2])\n",
    "    for i in range(len(event)):\n",
    "        event[i,2]=str(float(event[i,2])-offset_t)\n",
    "\n",
    "    feature=features[[max(0, index_-1), index_, min(len(features)-1, index_+2)]]\n",
    "    score=scores[index_]\n",
    "\n",
    "    changefea=[]\n",
    "    for col in range(feature.shape[1]):\n",
    "        fea=feature[:,col]\n",
    "        if max(fea)!=min(fea):\n",
    "            changefea.append([col]+list(fea))\n",
    "\n",
    "    print(index_, score, item[-1])\n",
    "    print({i:item for i, item in enumerate(sorted(set(events_all[:,0])))})\n",
    "    print(event)\n",
    "    print(np.round(changefea, 5))\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import packages\n",
    "\"\"\"\n",
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, random\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "import path, sys, re, time\n",
    "from collections import Counter\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import custom modules\n",
    "\"\"\"\n",
    "from module_.readText import read_hh\n",
    "from module_.featureExtraction import feature_extraction\n",
    "from module_.changePointDetection import change_point_detection\n",
    "from module_.info.hh101_info import baseline_activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hh101 (CASAS, 1-resident, serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "0. load casas dataset: hh101\n",
    "\"\"\"\n",
    "# with open('dataset/hh/hh101/ann.txt','rb') as f: \n",
    "#     rawdata=f.readlines()\n",
    "# events=read_hh(rawdata)\n",
    "# events=np.array(events)\n",
    "events=np.load(\"./preprocessed/test/ann.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. remove all except M and D\n",
    "\"\"\"\n",
    "events_md=np.array([event for event in events if event[0][0] in ['M', 'D']])\n",
    "print(events_md.shape)\n",
    "\n",
    "trs_md=[i for i in range(len(events_md)) if events_md[i][3]!=events_md[max(i-1,0)][3]]\n",
    "print(len(trs_md))\n",
    "\n",
    "for i in range(events_md.shape[0]):\n",
    "    events_md[i,3]='Idle' if events_md[i,3]==\"\" else events_md[i,3]\n",
    "\n",
    "episodes, trs, tags = [], [], []\n",
    "previdx=0\n",
    "for i in range(len(trs_md)-1):\n",
    "    # left activity\n",
    "    # right activity\n",
    "    left=np.array(events_md[previdx:trs_md[i]])\n",
    "    right=np.array(events_md[trs_md[i]:trs_md[i+1]])\n",
    "    episode=np.concatenate((left, right))\n",
    "    # print(episode.shape)\n",
    "    episodes.append(episode)\n",
    "    trs.append(left.shape[0])\n",
    "    tags.append(\"{}-{}\".format(left[0][3], right[0][3]))\n",
    "\n",
    "    previdx=trs_md[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"make combinations\n",
    "    1. pick one group type\n",
    "    2. pick an activity stream from the group\n",
    "    3. pick another group type w/o type 1.\n",
    "    4. pick an activity stream from the group\n",
    "\"\"\"\n",
    "\n",
    "data_name='hh101'\n",
    "metric='SEP'\n",
    "\n",
    "for i, eps in enumerate(episodes):\n",
    "    print(i, tags[i])\n",
    "    sensor_list=sorted(set(eps[:,0]))\n",
    "    features=feature_extraction(eps, data_name, sensor_list)\n",
    "    scores=change_point_detection(features, i, tags[i], data_name=data_name, metric=metric, save=True)\n",
    "    scores=np.array(scores)\n",
    "    scores[scores<0]=0\n",
    "\n",
    "    peak, _ =find_peaks(scores)\n",
    "    peak=[p for p in peak if scores[p]>0.1]\n",
    "    \n",
    "    positive=[]\n",
    "    latest_timestamp=None\n",
    "    for pp, pidx in enumerate(peak):\n",
    "        if pp==0:\n",
    "            latest_timestamp=float(eps[pidx][2])\n",
    "            positive.append(pidx)\n",
    "        else:\n",
    "            counterpart_timestamp=float(eps[pidx][2])\n",
    "            if abs(latest_timestamp-counterpart_timestamp)>20:\n",
    "                positive.append(pidx)\n",
    "                latest_timestamp=counterpart_timestamp\n",
    "\n",
    "###\n",
    "    plt.title(\"{}-{}\".format(tags[i], i))\n",
    "    plt.ylabel('score')\n",
    "    plt.xlabel('event')\n",
    "    plt.ylim(0,0.7)\n",
    "    # plt.bar(range(len(scores)), scores)\n",
    "    # plt.plot(positive, scores[positive], 'bx', label='peak')\n",
    "    plt.bar(positive, scores[positive], color='b')\n",
    "    plt.axhline(y=0.1, linestyle=':', color='r', label='threshold')\n",
    "    plt.axvline(x=trs[i], linestyle=':', color='g', label='transition')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"./outputs/{}/{}/{}/{}/graph.png\".format(data_name, metric, tags[i], i))\n",
    "    # plt.clf()\n",
    "\n",
    "    break\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    hh101 Evaluation\n",
    "    - load scores\n",
    "\"\"\"\n",
    "\n",
    "data_name='hh101'\n",
    "metric='SEP'\n",
    "\n",
    "total_counts=np.zeros(4)\n",
    "denom = numer = 0\n",
    "for activity_folder in glob.glob(\"./outputs/{}/{}/*\".format(data_name, metric)):\n",
    "    # one type of pairs\n",
    "    activity_pair=activity_folder.split(\"/\")[-1]\n",
    "    print(activity_pair)\n",
    "    pair_counts=np.zeros(4) # TP, FP, TN, FN\n",
    "\n",
    "    for episode_folder in glob.glob(\"{}/*\".format(activity_folder)):\n",
    "        denom+=1\n",
    "        eps_order=int(episode_folder.split(\"/\")[-1])\n",
    "        eps, point=episodes[eps_order], trs[eps_order]\n",
    "        scores=np.load(\"{}/scores.npy\".format(episode_folder))\n",
    "\n",
    "        peaks, _ = find_peaks(scores)\n",
    "        positives=[i for i in peaks if scores[i]>0.1]\n",
    "        numer+=len(positives)\n",
    "        # positives=[i for i in range(len(scores)) if scores[i]>0.3]\n",
    "        ttimestamp=float(eps[point][2])\n",
    "\n",
    "        for i in range(len(scores)):\n",
    "            if i in positives:\n",
    "                if i==point:\n",
    "                    pair_counts[0]+=1\n",
    "                else:\n",
    "                    timestamp_b=float(eps[i-1][2])\n",
    "                    timestamp_a=float(eps[i][2])\n",
    "                    if abs(ttimestamp-timestamp_b)<10 or abs(ttimestamp-timestamp_a)<10:\n",
    "                        pair_counts[0]+=1\n",
    "                    else:\n",
    "                        pair_counts[1]+=1\n",
    "            else:\n",
    "                if i==point:\n",
    "                    pair_counts[3]+=1\n",
    "                else:\n",
    "                    pair_counts[2]+=1\n",
    "    TPR_=pair_counts[0]/(pair_counts[0]+pair_counts[3])\n",
    "    FPR_=pair_counts[1]/(pair_counts[1]+pair_counts[2])\n",
    "    print(\"Avg. TPR and FPR: ({}, {})\".format(TPR_, FPR_))\n",
    "\n",
    "    total_counts+=pair_counts\n",
    "\n",
    "TPR=total_counts[0]/(total_counts[0]+total_counts[3])\n",
    "FPR=total_counts[1]/(total_counts[1]+total_counts[2])\n",
    "print(\"Total Avg. TPR and FPR: ({}, {})\".format(TPR, FPR))\n",
    "\n",
    "print(numer/denom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import packages and modules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os, glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, random\n",
    "import datetime as dt\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "import path, sys, re, time\n",
    "from collections import Counter\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "\n",
    "from module_.info.testbed import activityfiles_new\n",
    "from module_.info.config import config, feature_name\n",
    "from module_.readText import create_episodes, time_correction, read_adlmr\n",
    "from module_.featureExtraction import feature_extraction\n",
    "from module_.changePointDetection import change_point_detection"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from module_.correlation import correlation\n",
    "\n",
    "correlation(\"SEP\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0/47 Chatting0TechnicalDiscussion0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 720x72 with 0 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## testbed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dir_=\"dataset/testbed/npy/seminar/MS\"\n",
    "task_dict={i:[np.load(\"{}/{}\".format(dir_, name)) for name in v] for i, v in enumerate(activityfiles_new.values())}\n",
    "initial_dict={i:k[0] for i, k in enumerate(activityfiles_new.keys())}\n",
    "label_dict={k[0]:k for k in activityfiles_new.keys()}\n",
    "\n",
    "episodes, trs, tags = create_episodes(task_dict, initial_dict)\n",
    "episodes=[time_correction(eps, trs[i]) for i, eps in enumerate(episodes)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# view_size = 5\n",
    "\n",
    "test_idx = 12\n",
    "test_chunk = episodes[test_idx]\n",
    "transitions = [trs[test_idx]]\n",
    "\n",
    "sensor_list = sorted(set(test_chunk[:,0]))\n",
    "\n",
    "prev_box = {sensor_:None for sensor_ in sensor_list} # Previous state for comparison (If no difference, no update)\n",
    "\n",
    "features = []\n",
    "\n",
    "prev_matrix = np.ones((len(sensor_list), len(sensor_list)))\n",
    "correlation_matrix = np.ones((len(sensor_list), len(sensor_list)))\n",
    "\n",
    "\n",
    "dict_timestamps={} # Memory of Each sensor's previous timestamp\n",
    "\n",
    "first_timestamp = float(test_chunk[0][2])-1\n",
    "\n",
    "l = []\n",
    "for i, event in enumerate(test_chunk):\n",
    "    feature = []\n",
    "    sensor = event[0]\n",
    "    timestamp = float(event[2])\n",
    "\n",
    "    if sensor not in dict_timestamps.keys():\n",
    "        dict_timestamps[sensor]=[first_timestamp, timestamp]\n",
    "    else:\n",
    "        dict_timestamps[sensor].append(timestamp)\n",
    "\n",
    "    index_r = sensor_list.index(sensor) # Current sensor\n",
    "    sensor_x = dict_timestamps[sensor] # Current sensor's timestamps\n",
    "    # sensor_x = dict_timestamps[sensor][-view_size:]\n",
    "\n",
    "    # Update correlation with other sensors\n",
    "    for sensor_ in dict_timestamps.keys():\n",
    "        if sensor_==sensor:\n",
    "            continue\n",
    "        # sensor_y = dict_timestamps[sensor_][-view_size:]\n",
    "        sensor_y = dict_timestamps[sensor_] # Other sensor's timestamp\n",
    "\n",
    "        min_length = min(len(sensor_x), len(sensor_y))\n",
    "\n",
    "        if min_length == 0: # Not enough data\n",
    "            continue\n",
    "        else:\n",
    "            sensor_x_ = sensor_x[-min_length:]\n",
    "            sensor_y_ = sensor_y[-min_length:]\n",
    "\n",
    "        assert len(sensor_x_)==len(sensor_y_)\n",
    "\n",
    "        index_c = sensor_list.index(sensor_) # The other sensor\n",
    "\n",
    "        if False:\n",
    "            correlation_matrix[index_r, index_c] = prev_matrix[index_r, index_c]\n",
    "            correlation_matrix[index_c, index_r] = prev_matrix[index_r, index_c]\n",
    "        else:\n",
    "            correl = np.corrcoef(sensor_x_, sensor_y_)[0,1]#; print(sensor_x_, sensor_y_, sensor, sensor_, correl)\n",
    "            if not np.isnan(correl): # variance = 0\n",
    "                correlation_matrix[index_r, index_c]=correl\n",
    "                correlation_matrix[index_c, index_r]=correl\n",
    "\n",
    "                prev_matrix[index_r, index_c] = correl\n",
    "                prev_matrix[index_c, index_r] = correl\n",
    "\n",
    "                prev_box[sensor_] = sensor_y\n",
    "\n",
    "    l.append(np.mean(correlation_matrix[index_r]))\n",
    "\n",
    "print(len(test_chunk), len(l))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 1))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.plot(range(len(l)), l)\n",
    "for t in transitions:\n",
    "    plt.axvline(x=t, linestyle=':', color='g')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "window_size = 30\n",
    "metric = 'RuLSIF'\n",
    "features = []\n",
    "for i in range(len(l)):\n",
    "    bucket=[]\n",
    "    idx=i-window_size+1\n",
    "    while idx<=i:\n",
    "        bucket.append(l[max(0, idx)])\n",
    "        idx+=1\n",
    "    \n",
    "    features.append(bucket)\n",
    "\n",
    "print(np.array(features).shape)\n",
    "\n",
    "scores = np.array(change_point_detection(features, metric))\n",
    "# scores[scores<0] = 0\n",
    "assert len(scores) == len(l)\n",
    "plt.bar(range(len(scores)), scores)\n",
    "for t in transitions:\n",
    "    plt.axvline(x=t, linestyle=':', color='g')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ll = []\n",
    "for i in range(len(l)-1):\n",
    "    ll.append(abs(l[i]-l[i+1]))\n",
    "ll = np.array(ll)\n",
    "\n",
    "plt.bar(range(len(ll)), ll)\n",
    "for t in transitions:\n",
    "    plt.axvline(x=t, linestyle=':', color='g')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sorted(set(test_chunk[:,0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## adlmr"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "f = open(\"./dataset/adlmr/annotated\", 'rb')\n",
    "text = f.readlines()\n",
    "tasks = read_adlmr(text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## hh"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load dataset\n",
    "directory_hh101=\"./dataset/hh/hh101/ann.txt\"\n",
    "\n",
    "f=open(directory_hh101, 'r')\n",
    "txt=f.readlines()\n",
    "events=[]\n",
    "activity = \"Idle\"\n",
    "for i, line in enumerate(txt):\n",
    "    event = []\n",
    "    \n",
    "    try:\n",
    "        f_info = line.split()\n",
    "        # Date, time, sensor, value, (label)\n",
    "\n",
    "        event.append(f_info[2])\n",
    "        event.append(f_info[3])\n",
    "        if not ('.' in str(np.array(f_info[0])) + f_info[1]):\n",
    "            f_info[1] = f_info[1] + '.000000'\n",
    "        timestamp=datetime.timestamp(datetime.strptime(f_info[0] + f_info[1], \"%Y-%m-%d%H:%M:%S.%f\"))\n",
    "        event.append(float(timestamp))           # 3. timestamp\n",
    "\n",
    "        if len(f_info) != 4: # label\n",
    "            label = str(' '.join(np.array(f_info[4:])))\n",
    "            if 'begin' in label:\n",
    "                activity = label.split('=')[0].strip()\n",
    "                event.append(activity)\n",
    "            elif 'end' in label:\n",
    "                event.append(activity)\n",
    "                activity = \"Idle\"\n",
    "            else:\n",
    "                event.append(activity)\n",
    "        else:\n",
    "            event.append(activity)\n",
    "        \n",
    "        events.append(event)\n",
    "\n",
    "    except:\n",
    "        print(\"SKIP\")\n",
    "\n",
    "raw_length = len(events)\n",
    "\n",
    "print(Counter(np.array(events)[:,3]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "events = [e for e in events if e[0][0] in list('MD')]\n",
    "\n",
    "startindices = [i for i in range(1, len(events)) if events[i][3]!=events[i-1][3]]\n",
    "startindices = [0]+startindices+[len(events)]\n",
    "\n",
    "dict_consecutiveActivities = {\n",
    "    'chunks':[],\n",
    "    'labels':[],\n",
    "    'lengths':[],\n",
    "}\n",
    "\n",
    "chunksize = 8\n",
    "\n",
    "CoC=[]\n",
    "CoLbl=[]\n",
    "CoLen=[]\n",
    "for i in range(len(startindices)-1):\n",
    "    start, end_ = startindices[i:i+2]\n",
    "    chunk=events[start:end_]\n",
    "\n",
    "    labelset = list(set(np.array(chunk)[:,3]))\n",
    "    assert len(labelset)==1\n",
    "    label = labelset[0]\n",
    "\n",
    "    if len(CoC)==chunksize:\n",
    "        dict_consecutiveActivities['chunks'].append(CoC)\n",
    "        dict_consecutiveActivities['labels'].append(CoLbl)\n",
    "        dict_consecutiveActivities['lengths'].append(CoLen)\n",
    "        # CoC = CoLbl = CoLen = []\n",
    "        CoC, CoLbl, CoLen = [], [], []\n",
    "\n",
    "    CoC.append(chunk)\n",
    "    CoLbl.append(label)\n",
    "    CoLen.append(len(chunk))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"Test: Second Chunks\"\"\"\n",
    "ti = 3\n",
    "test_chunk = np.concatenate(dict_consecutiveActivities['chunks'][ti])\n",
    "test_label = dict_consecutiveActivities['labels'][ti]\n",
    "test_length = dict_consecutiveActivities['lengths'][ti]\n",
    "\n",
    "print(test_chunk.shape, test_label, test_length)\n",
    "\n",
    "transitions = []\n",
    "start=0\n",
    "for i in range(len(test_length)-1):\n",
    "    transitions.append(start+test_length[i])\n",
    "    start+=test_length[i]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# window_size = 30\n",
    "view_size = 5\n",
    "\n",
    "sensor_list = sorted(set(test_chunk[:,0]))\n",
    "\n",
    "for sensor in sensor_list:\n",
    "    print(sensor, sensor_list.index(sensor))\n",
    "\n",
    "# correlation_matrix = np.diag(np.ones(len(sensor_list)))\n",
    "correlation_matrix = np.ones((len(sensor_list), len(sensor_list)))\n",
    "prev1_matrix = prev2_matrix = correlation_matrix\n",
    "dict_timestamps={}\n",
    "l = []\n",
    "r, c = (6, 3)\n",
    "for i, event in enumerate(test_chunk):\n",
    "    sensor = event[0]\n",
    "    timestamp = float(event[2])\n",
    "\n",
    "    if sensor not in dict_timestamps.keys():\n",
    "        dict_timestamps[sensor]=[timestamp]\n",
    "    else:\n",
    "        dict_timestamps[sensor].append(timestamp)\n",
    "    index_r = sensor_list.index(sensor)\n",
    "\n",
    "    sensor_x = dict_timestamps[sensor][-view_size:]\n",
    "    if len(sensor_x)<view_size:\n",
    "        l.append(1 if len(l)==0 else l[-1])\n",
    "        continue\n",
    "\n",
    "    for sensor_ in dict_timestamps.keys():\n",
    "        if sensor_==sensor:\n",
    "            continue\n",
    "        sensor_y = dict_timestamps[sensor_][-view_size:]\n",
    "        if len(sensor_y)<view_size:\n",
    "            continue\n",
    "        index_c = sensor_list.index(sensor_)\n",
    "        # col.append(np.corrcoef(sensor_x, sensor_y)[0,1])\n",
    "        correlation_matrix[index_r, index_c]=np.corrcoef(sensor_x, sensor_y)[0,1]\n",
    "        correlation_matrix[index_c, index_r]=np.corrcoef(sensor_x, sensor_y)[0,1]\n",
    "    l.append(np.average(correlation_matrix+prev1_matrix+prev2_matrix)/3)\n",
    "    prev2_matrix = prev1_matrix\n",
    "    prev1_matrix = correlation_matrix\n",
    "    \n",
    "print(len(test_chunk))\n",
    "print(len(l))\n",
    "    \n",
    "fig = plt.figure(figsize=(10, 1))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.plot(range(len(l)), l)\n",
    "for t in transitions:\n",
    "    plt.axvline(x=t, linestyle=':', color='g')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## testbed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
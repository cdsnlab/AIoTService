{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import packages and modules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, random\n",
    "import datetime as dt\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "import path, sys, re, time\n",
    "from collections import Counter\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "\n",
    "from module_.info.testbed import activityfiles_new\n",
    "from module_.info.config import config, feature_name\n",
    "from module_.readText import create_episodes, time_correction, read_adlmr\n",
    "from module_.featureExtraction import feature_extraction\n",
    "from module_.changePointDetection import change_point_detection\n",
    "\n",
    "from module_.correlation import module_pmc\n",
    "from module_.featureExtraction import sliding_window\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# CORRELATION\n",
    "from module_.correlation import correlation\n",
    "\n",
    "result = correlation(\"hh101\", None)\n",
    "# result = correlation(\"testbed\",\"RuLSIF\")\n",
    "# result = correlation(\"adlmr\",\"RuLSIF\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from module_.dataLoader import dataLoader\n",
    "\n",
    "dataset = \"testbed\"\n",
    "\n",
    "# episodes, transitions, labels = dataLoader(\"testbed\")\n",
    "episodes, transitions, labels = dataLoader(dataset)\n",
    "\n",
    "sensors = set()\n",
    "for episode in episodes:\n",
    "    sensors = sensors | set(episode[:,0])\n",
    "sensors = sorted(sensors)\n",
    "\n",
    "# episodes, transitions, labels = dataLoader(\"hh101\")\n",
    "# episodes = np.load(\"./dataload/hh101/episodes.npy\", allow_pickle=True)\n",
    "# transitions = np.load(\"./dataload/hh101/transitions.npy\")\n",
    "# labels = np.load(\"./dataload/hh101/labels.npy\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# active state\n",
    "\n",
    "from module_.validation import check_active_state\n",
    "\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "ax = plt.axes()\n",
    "\n",
    "colorstring = \"bgrcmk\"\n",
    "\n",
    "threshold = 60\n",
    "\n",
    "for d, folder in enumerate(glob(\"./correlation/testbed/*\")):\n",
    "    \n",
    "    if d!=1:\n",
    "        continue\n",
    "    print(folder)\n",
    "    pair = folder.split(\"/\")[-1].split(\".\")[0]\n",
    "    episode = np.load(\"{}/episode.npy\".format(folder))\n",
    "    transition = np.load(\"{}/label.npy\".format(folder))[0]\n",
    "\n",
    "    start_time = float(episode[0,2])\n",
    "    transition_time_l = float(episode[transition-1,2])-start_time\n",
    "    transition_time_r = float(episode[transition,2])-start_time\n",
    "\n",
    "    correlation = np.load(\"{}/relationships.npy\".format(folder))\n",
    "\n",
    "    active_dict = check_active_state(episode)\n",
    "\n",
    "    ax.set_title('Active State of {}'.format(pair))\n",
    "    ax.set_xlabel(\"Timestamp\"); ax.set_ylabel(\"Sensor\")\n",
    "    ax.set_yticks(range(1, len(active_dict.keys())+1))\n",
    "    ax.set_yticklabels(active_dict.keys())\n",
    "\n",
    "    for i, item in enumerate(active_dict.items()):\n",
    "        k, v = item\n",
    "        for fragment in v:\n",
    "            # if fragment[0]>transition_time_l-600 and fragment[1]<transition_time_r+600:\n",
    "            ax.hlines(y=i+1, xmin=fragment[0], xmax=fragment[1], linewidth=3, color=colorstring[i%len(colorstring)-1])\n",
    "    \n",
    "    plt.axvline(\n",
    "        x=transition_time_l, color=\"g\", linestyle=\":\"\n",
    "    )\n",
    "    plt.axvline(\n",
    "        x=transition_time_r, color=\"g\", linestyle=\":\"\n",
    "    )\n",
    "    plt.axvspan(max(0, transition_time_l-threshold), min(transition_time_r+threshold, float(episode[-1,2])-float(episode[0,2])), \n",
    "        facecolor='g', alpha=0.2, label=\"transition\"\n",
    "    )\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# relationships = np.load(\"./correlation/testbed/npy/GroupStudy-Presentation-Discussion-Chatting_correlation.npy\")\n",
    "# relationships = np.load(\"./correlation/adlmr/npy/GA-GB-GC-GD-GE-GA-GB-GC-GD-GE_correlation.npy\")\n",
    "# relationships = np.load(\"./correlation/hh101/npy/Personal_Hygiene-Other_correlation.npy\")\n",
    "\n",
    "index = 0\n",
    "episode, transition, label = episodes[index], transitions[index], labels[index]\n",
    "\n",
    "relationships = module_pmc(episode, 0, sensors)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for ei in range(len(episode)):\n",
    "    s, v, t, _ = episode[ei]\n",
    "    print(ei, s)\n",
    "    si = sensors.index(s)\n",
    "    row = relationships[ei][si]\n",
    "    for ri in range(len(row)):\n",
    "        if row[ri]!=1.:\n",
    "            ps = sensors[ri]\n",
    "            print(ps, np.trunc(row[ri]*1e3)/1e3, end=\" \")\n",
    "    print()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i, event in enumerate(episode):\n",
    "    print(i, event)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# MEAN RELATIONSHIPS\n",
    "\n",
    "mean_relationships = [np.mean(item) for item in relationships]\n",
    "\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "plt.title(label)\n",
    "plt.bar(range(len(mean_relationships)), mean_relationships)\n",
    "plt.ylim(min(mean_relationships), 1)\n",
    "# plt.bar(range(len(weighted_relationships)), weighted_relationships)\n",
    "# plt.ylim(min(weighted_relationships), 1)\n",
    "if type(transition)!=list:\n",
    "    transition = [transition]\n",
    "for trans in transition:\n",
    "    lb, ub = trans-1, trans\n",
    "    tl, tr = float(episode[lb,2]), float(episode[ub,2])\n",
    "    while tl-float(episode[lb,2])<10. and lb!=0:\n",
    "        lb-=1\n",
    "    while float(episode[ub,2])-tr<10. and ub!=len(episode)-1:\n",
    "        ub+=1\n",
    "    plt.axvline(\n",
    "        trans, linestyle=\"dotted\", color=\"g\"\n",
    "    )\n",
    "    plt.axvspan(\n",
    "        lb, ub, alpha=0.2, color='g'\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# CHANGES\n",
    "\n",
    "mean_relationships = [np.mean(item) for item in relationships]\n",
    "\n",
    "window_size = 30\n",
    "windows = sliding_window(mean_relationships, window_size)\n",
    "\n",
    "\n",
    "values = []\n",
    "slopes = []\n",
    "for i in range(len(windows)):\n",
    "    meanvalue = np.mean(windows[i])\n",
    "    diff = sum(abs(np.array(windows[i])-meanvalue))\n",
    "    values.append(diff)\n",
    "\n",
    "    if len(values)>=window_size:\n",
    "        y = np.array(values[-window_size:])\n",
    "        A = np.vstack([np.array([k/10. for k in range(window_size)]), np.ones(window_size)]).T\n",
    "    else:\n",
    "        y = np.array(values)\n",
    "        A = np.vstack([np.array([k/10. for k in range(len(values))]), np.ones(len(values))]).T\n",
    "    m, _ = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "    slopes.append(max(0, m))\n",
    "    # slopes.append(m)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "plt.title(label)\n",
    "plt.bar(range(len(values)), values)\n",
    "\n",
    "if type(transition)!=list:\n",
    "    transition = [transition]\n",
    "for trans in transition:\n",
    "    lb, ub = trans-1, trans\n",
    "    tl, tr = float(episode[lb,2]), float(episode[ub,2])\n",
    "    while tl-float(episode[lb,2])<10. and lb!=0:\n",
    "        lb-=1\n",
    "    while float(episode[ub,2])-tr<10. and ub!=len(episode)-1:\n",
    "        ub+=1\n",
    "    plt.axvline(\n",
    "        trans, linestyle=\"dotted\", color=\"g\"\n",
    "    )\n",
    "    plt.axvspan(\n",
    "        lb, ub, alpha=0.2, color='g'\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SLOPE\n",
    "\n",
    "slopes = np.array(slopes)\n",
    "slopes[slopes<0]=0\n",
    "\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "plt.title(label)\n",
    "plt.bar(range(len(slopes)), slopes)\n",
    "if type(transition)!=list:\n",
    "    transition = [transition]\n",
    "for trans in transition:\n",
    "    lb, ub = trans-1, trans\n",
    "    tl, tr = float(episode[lb,2]), float(episode[ub,2])\n",
    "    while tl-float(episode[lb,2])<10. and lb!=0:\n",
    "        lb-=1\n",
    "    while float(episode[ub,2])-tr<10. and ub!=len(episode)-1:\n",
    "        ub+=1\n",
    "    plt.axvline(\n",
    "        trans, linestyle=\"dotted\", color=\"g\"\n",
    "    )\n",
    "    plt.axvspan(\n",
    "        lb, ub, alpha=0.2, color='g'\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# PEAK\n",
    "\n",
    "flow = False\n",
    "prevflow = previdx = 0\n",
    "peaks = []\n",
    "for i in range(len(slopes)):\n",
    "    if flow:\n",
    "        if slopes[i]==0.:\n",
    "            continue\n",
    "        if slopes[i]>prevflow: # Increasing\n",
    "            prevflow = slopes[i]\n",
    "            previdx = i\n",
    "        else:\n",
    "            peaks.append(previdx) # peak\n",
    "            flow=False\n",
    "    else:\n",
    "        if slopes[i]>0.:\n",
    "            flow=True\n",
    "            prevflow = slopes[i]\n",
    "            previdx = i\n",
    "    \n",
    "\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "peakslope = [slopes[i] if i in peaks else 0 for i in range(len(slopes)) ]\n",
    "peakslope = np.array(peakslope)\n",
    "\n",
    "# peakslope[peakslope<0.075]=0\n",
    "\n",
    "plt.title(label)\n",
    "plt.bar(range(len(peakslope)), peakslope)\n",
    "if type(transition)!=list:\n",
    "    transition = [transition]\n",
    "for trans in transition:\n",
    "    lb, ub = trans-1, trans\n",
    "    tl, tr = float(episode[lb,2]), float(episode[ub,2])\n",
    "    while tl-float(episode[lb,2])<10. and lb!=0:\n",
    "        lb-=1\n",
    "    while float(episode[ub,2])-tr<10. and ub!=len(episode)-1:\n",
    "        ub+=1\n",
    "    plt.axvline(\n",
    "        trans, linestyle=\"dotted\", color=\"g\"\n",
    "    )\n",
    "    plt.axvspan(\n",
    "        lb, ub, alpha=0.2, color='g'\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EVENT SEQUENCE\n",
    "\n",
    "from scipy.spatial import distance_matrix\n",
    "score = peakslope\n",
    "print(transition)\n",
    "print([i for i in range(len(score)) if score[i]>=0.02])\n",
    "enumber = 620\n",
    "print(score[enumber])\n",
    "\n",
    "lb, ub = max(0, enumber-45+1), min(enumber+2+1, len(episode))\n",
    "data = episode[lb:ub]\n",
    "for i, datum in enumerate(data):\n",
    "    # print(f\"{i+lb} {datum[0]}, {datum[1]}, {datum[2]}, {datum[3]}, {datum[4]}\")\n",
    "    print(f\"{i+lb} {datum[0]}, {datum[1]}, {datum[2]}\")\n",
    "# diff_feature"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "window_size = 30\n",
    "\n",
    "tslopes = []\n",
    "tpeaks = []\n",
    "\n",
    "for epi in range(len(episodes)):\n",
    "\n",
    "    episode, transition, label = episodes[epi], transitions[epi], labels[epi]\n",
    "\n",
    "    relationships = module_pmc(episode, 0, sensors)\n",
    "\n",
    "    # mean_relationships = [np.mean(item) for item in relationships]\n",
    "    assert len(episode)==len(relationships)\n",
    "\n",
    "    weighted_relationships = []\n",
    "    for ri in range(len(relationships)):\n",
    "        matrix = relationships[ri]\n",
    "        esi = sensors.index(episode[ri][0])\n",
    "        weight_vector = matrix[esi]\n",
    "        weighted_sum = np.zeros(len(sensors))\n",
    "        for si in range(len(matrix)):\n",
    "            if esi==si:\n",
    "                continue\n",
    "            weighted_sum += matrix[si]*weight_vector[si]\n",
    "        weighted_relationships.append(sum(weighted_sum))\n",
    "\n",
    "\n",
    "\n",
    "    windows = sliding_window(weighted_relationships, window_size)\n",
    "\n",
    "    values = []\n",
    "    slopes = []\n",
    "    for i in range(len(windows)):\n",
    "        meanvalue = np.mean(windows[i])\n",
    "        diff = sum(abs(np.array(windows[i])-meanvalue))\n",
    "        values.append(diff)\n",
    "\n",
    "        if len(values)>=window_size:\n",
    "            y = np.array(values[-window_size:])\n",
    "            # A = np.vstack([np.array([(float(episode[k][2])-float(episode[0][2])) for k in range(max(0, i-window_size+1), i+1)]), np.ones(window_size)]).T\n",
    "            A = np.vstack([np.array([k/10. for k in range(max(0, i-window_size+1), i+1)]), np.ones(window_size)]).T\n",
    "        else:\n",
    "            y = np.array(values)\n",
    "            A = np.vstack([np.array([k/10. for k in range(len(values))]), np.ones(len(values))]).T\n",
    "            # A = np.vstack([np.array([(float(episode[k][2])-float(episode[0][2])) for k in range(len(values))]), np.ones(len(values))]).T\n",
    "        m, _ = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "        slopes.append(max(0, m))\n",
    "\n",
    "    flow = False\n",
    "    prevflow = previdx = 0\n",
    "    peaks = []\n",
    "    for i in range(len(slopes)):\n",
    "        if flow:\n",
    "            if slopes[i]==0.:\n",
    "                continue\n",
    "            if slopes[i]>prevflow: # Increasing\n",
    "                prevflow = slopes[i]\n",
    "                previdx = i\n",
    "            else:\n",
    "                peaks.append(previdx) # peak\n",
    "                flow=False\n",
    "        else:\n",
    "            if slopes[i]>0.:\n",
    "                flow=True\n",
    "                prevflow = slopes[i]\n",
    "                previdx = i\n",
    "\n",
    "    peakslope = [slopes[i] if i in peaks else 0 for i in range(len(slopes)) ]\n",
    "    peakslope = np.array(peakslope)\n",
    "\n",
    "    plt.plot(range(len(peakslope)), peakslope)\n",
    "    plt.axvline()\n",
    "\n",
    "\n",
    "    break\n",
    "\n",
    "    tslopes.append(slopes)\n",
    "    tpeaks.append(peaks)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    # peakslopes.append([p for p in peaks if slopes[p]>threshold])\n",
    "    # print([i for i in range(len(peakslope)) if peakslope[i]>0.02])\n",
    "# np.save(f\"./correlation/{dataset}/npy/slopes_{window_size}.npy\", tslopes)\n",
    "# np.save(f\"./correlation/{dataset}/npy/peaks_{window_size}.npy\", tpeaks)\n",
    "# np.save(f\"./correlation/adlmr/npy/peaks_{threshold}.npy\", peakslopes)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/kisoo/.local/lib/python3.8/site-packages/numpy/lib/function_base.py:2634: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/kisoo/.local/lib/python3.8/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/kisoo/.local/lib/python3.8/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/kisoo/.local/lib/python3.8/site-packages/numpy/lib/function_base.py:2642: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/kisoo/.local/lib/python3.8/site-packages/numpy/lib/function_base.py:2643: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "0. 실험한 결과\n",
    "문제점 1. 전환점(t) 으로부터 Window size (ws) 만큼 뒤에서 포착 (t+ws)되기 때문에 상당한 Delay가 존재한다\n",
    "문제점 2. Dataset마다 다른 Window size를 적용해야 한다 (센서의 발현 주기가 다르기 때문에, 너무 작게 설정하면 Peak를 많이 발생시키고 너무 크게 설정하면 Peak를 못 잡기도 한다)\n",
    "문제점 3. 기울기 Threshold을 고정값으로 설정하기가 어렵다\n",
    "    - 특정한 두 연속된 행동에 대해서 전환점을 찾으려 할때, 변화하는 센서의 수에 따라서 변화의 기울기가 가파르게 나타나기도 하고 느슨하게 나타나기도 한다\n",
    "    - 기울기를 변화에 관여한 센서의 수에 비례하게 계산할 수 있는 방법이 필요한데."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "slopes = np.load(f\"./correlation/{dataset}/npy/slopes_{window_size}.npy\", allow_pickle=True)\n",
    "peaks = np.load(f\"./correlation/{dataset}/npy/peaks_{window_size}.npy\", allow_pickle=True)\n",
    "\n",
    "threshold = 0.015\n",
    "\n",
    "assert len(slopes)==len(peaks)\n",
    "\n",
    "tp = tn = fp = fn = 0\n",
    "\n",
    "for epi in range(len(episodes)):\n",
    "    episode, transition, label = episodes[epi], transitions[epi], labels[epi]\n",
    "    slope, peak = slopes[epi], peaks[epi]\n",
    "\n",
    "    peak_ = [p for p in peak if slope[p]>threshold]\n",
    "\n",
    "    etp = etn = efp = efn = 0\n",
    "\n",
    "    lb, ub = transition-1, transition\n",
    "    lbt, ubt = float(episode[lb][2]), float(episode[ub][2])\n",
    "    for ei in range(len(episode)):\n",
    "        if dataset==\"adlmr\":\n",
    "            s, v, t, _, _ = episode[ei]\n",
    "        else:\n",
    "            s, v, t = episode[ei]\n",
    "        if ei in peak_: # POSITIVE\n",
    "            # if abs(float(t)-lbt)<10. or abs(float(t)-ubt)<10.:\n",
    "            if abs(ei-ub)<15:\n",
    "                etp+=1\n",
    "            else:\n",
    "                efp+=1\n",
    "        else: # NEGATIVE\n",
    "            if ei==lb or ei==ub:\n",
    "                efn+=1\n",
    "            else:\n",
    "                etn+=1\n",
    "    \n",
    "    if etp!=0:\n",
    "        etp=1\n",
    "        efn=0\n",
    "    else:\n",
    "        etp=0\n",
    "        efn=1\n",
    "    tp+=etp; tn+=etn; fp+=efp; fn+=efn\n",
    "\n",
    "    \n",
    "print(tp/len(episodes), fp/len(episodes))\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6666666666666666 50.416666666666664\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(transition, [i for i in peaks if slopes[i]>0.02])\n",
    "idx = 64\n",
    "print(episode[idx-30:idx+1])"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
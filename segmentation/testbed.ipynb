{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import packages\n",
    "\"\"\"\n",
    "import os, glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, random\n",
    "import datetime as dt\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "import path, sys, re, time\n",
    "from collections import Counter\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import custom packages\n",
    "\"\"\"\n",
    "from module_.info.testbed import activityfiles_new\n",
    "from module_.info.config import config, feature_name\n",
    "from module_.readText import create_episodes, time_correction\n",
    "from module_.featureExtraction import feature_extraction\n",
    "from module_.changePointDetection import change_point_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testbed (Seminar, multi-resident, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load raw files\n",
    "\"\"\"\n",
    "\n",
    "dir_=\"dataset/testbed/npy/seminar/MS\"\n",
    "task_dict={i:[np.load(\"{}/{}\".format(dir_, name)) for name in v] for i, v in enumerate(activityfiles_new.values())}\n",
    "initial_dict={i:k[0] for i, k in enumerate(activityfiles_new.keys())}\n",
    "label_dict={k[0]:k for k in activityfiles_new.keys()}\n",
    "\n",
    "episodes, trs, tags = create_episodes(task_dict, initial_dict)\n",
    "episodes=[time_correction(eps, trs[i]) for i, eps in enumerate(episodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "1000/1478 (accumulated) time: 9.71076226234436\n",
      "1000/1034 (accumulated) time: 9.52949047088623\n",
      "1000/1600 (accumulated) time: 9.424732208251953\n",
      "1000/1156 (accumulated) time: 9.489741086959839\n",
      "1000/1095 (accumulated) time: 9.16968560218811\n",
      "1000/1478 (accumulated) time: 9.152300119400024\n",
      "1000/1600 (accumulated) time: 9.226066827774048\n",
      "1000/1866 (accumulated) time: 9.270823955535889\n",
      "1000/1473 (accumulated) time: 9.239261388778687\n",
      "1000/1533 (accumulated) time: 9.2349271774292\n",
      "1000/1441 (accumulated) time: 9.383036136627197\n",
      "1000/1034 (accumulated) time: 9.219940423965454\n",
      "1000/1156 (accumulated) time: 9.10584020614624\n",
      "1000/1095 (accumulated) time: 9.405786514282227\n",
      "1000/1866 (accumulated) time: 9.168402910232544\n",
      "1000/1089 (accumulated) time: 9.345455169677734\n",
      "1000/1473 (accumulated) time: 8.994776487350464\n",
      "1000/1533 (accumulated) time: 9.75435209274292\n",
      "1000/1089 (accumulated) time: 9.540658235549927\n",
      "1000/1441 (accumulated) time: 9.021901369094849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_name = 'testbed'\n",
    "metric = 'RuLSIF'\n",
    "\n",
    "folder = \"./features/{}\".format(data_name)\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(15, 15))\n",
    "\n",
    "sensor_set=set()\n",
    "\n",
    "for _, v in task_dict.items():\n",
    "    for v_ in v:\n",
    "        sensor_set = sensor_set | set(np.array(v_)[:,0])\n",
    "sensor_list=sorted(sensor_set)\n",
    "print(len(sensor_list))\n",
    "\n",
    "for ei, eps in enumerate(episodes):\n",
    "    activityfolder=\"{}/{}\".format(folder, tags[ei])\n",
    "    if not os.path.exists(activityfolder):\n",
    "        os.mkdir(activityfolder)\n",
    "    eps=np.array(eps)\n",
    "\n",
    "    # afolder=\"{}/{}\".format(activityfolder, ei)\n",
    "    # if not os.path.exists(afolder):\n",
    "    #     os.mkdir(afolder)\n",
    "    \n",
    "    features = np.array(feature_extraction(eps, data_name, sensor_list))\n",
    "\n",
    "    assert len(eps)==len(features)\n",
    "    \n",
    "    x_ = range(len(eps))\n",
    "\n",
    "    scores = np.array(change_point_detection(features, \"\", data_name, metric))\n",
    "    scores[scores<0]=0\n",
    "\n",
    "    assert len(eps)==len(scores)\n",
    "\n",
    "    names = list(feature_name.values())\n",
    "    numbasicfeatures = len(names)-2\n",
    "\n",
    "    for fi in range(numbasicfeatures):\n",
    "        ax_ = fig.add_subplot(numbasicfeatures+1, 1, fi+1)\n",
    "        ax_.plot(x_, features[:,fi], '.-')\n",
    "        ax_.axvline(trs[ei], linestyle=':', color='r')\n",
    "        ax_.set_ylabel(names[fi])\n",
    "        ax_.set_ylim(0,2)\n",
    "    ax_ = fig.add_subplot(numbasicfeatures+1, 1, numbasicfeatures+1)\n",
    "    ax_.bar(x_, scores, color='g')\n",
    "    ax_.axvline(trs[ei], linestyle=':', color='r')\n",
    "    ax_.set_ylabel(metric)\n",
    "    ax_.set_ylim(0,1)\n",
    "    fig.savefig(\"{}/feature_basic.png\".format(activityfolder))\n",
    "    fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"make combinations\n",
    "    1. pick one group type\n",
    "    2. pick an activity stream from the group\n",
    "    3. pick another group type w/o type 1.\n",
    "    4. pick an activity stream from the group\n",
    "\"\"\"\n",
    "data_name='testbed'\n",
    "preprocess='MS'\n",
    "metric='SEP'\n",
    "\n",
    "time_threshold=30\n",
    "score_threshold=0.1\n",
    "\n",
    "for i, eps in enumerate(episodes):\n",
    "\n",
    "    if i%100==0:\n",
    "        print(\"{}/{}\".format(i, len(episodes)))\n",
    "\n",
    "    pairname=\"{}-{}\".format(label_dict[tags[i][0]], label_dict[tags[i][2]])\n",
    "\n",
    "    pairfolder=\"./outputs/testbed/{}/{}\".format(preprocess, pairname)\n",
    "    if not os.path.exists(pairfolder):\n",
    "        os.mkdir(pairfolder)\n",
    "    epsfolder=\"{}/{}_{}_{}\".format(pairfolder, i, tags[i], trs[i])\n",
    "    if not os.path.exists(epsfolder):\n",
    "        os.mkdir(epsfolder)\n",
    "    \n",
    "    \n",
    "    # np.save(\"{}/events.npy\".format(epsfolder), eps)\n",
    "\n",
    "    sensor_list=sorted(set(eps[:,0]))\n",
    "    features=feature_extraction(eps, data_name, sensor_list)\n",
    "    # np.save(\"{}/features.npy\".format(epsfolder), features)\n",
    "\n",
    "    # featurefile=open(\"{}/feature_lasttime.txt\".format(epsfolder), 'w')\n",
    "    # featurefile.write(\"{}\\n\".format(sensor_list))\n",
    "    # for featurevector in features:\n",
    "    #     featurefile.write(\"{}\\n\".format(np.round(featurevector[12+len(sensor_list):], 2)))\n",
    "    # featurefile.close()\n",
    "\n",
    "    # continue\n",
    "    \n",
    "    scores=change_point_detection(features, epsfolder, data_name=data_name, metric=metric, save=False)\n",
    "    scores=np.array(scores)\n",
    "    scores[scores<0]=0\n",
    "\n",
    "    # positives=[idx for idx in range(len(scores)) if scores[idx]>score_threshold]\n",
    "\n",
    "    # peaks=[]\n",
    "    # prevPeakTimestamp=-1\n",
    "    # for p in positives:\n",
    "    #     if prevPeakTimestamp==-1 or float(eps[p][2])-prevPeakTimestamp>=time_threshold*2:\n",
    "    #         peaks.append(p)\n",
    "    #         prevPeakTimestamp=float(eps[p][2])\n",
    "    \n",
    "###\n",
    "    plt.title(\"{} {}\".format(pairname, tags[i]))\n",
    "    plt.ylabel('score')\n",
    "    plt.xlabel('event')\n",
    "    plt.ylim(0,2)\n",
    "    # plt.plot(peaks, scores[peaks], 'rx')\n",
    "    plt.bar(range(len(eps)), scores)\n",
    "    plt.axhline(y=score_threshold, linestyle=':', color='c')\n",
    "    plt.axvline(x=trs[i], linestyle=':', color='g', label='transition')\n",
    "    plt.legend()\n",
    "\n",
    "    break\n",
    "    plt.savefig(\"{}/graph_lasttime.png\".format(epsfolder))\n",
    "    plt.clf()\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    hh101 Evaluation\n",
    "    - load scores\n",
    "\"\"\"\n",
    "\n",
    "data_name='testbed'\n",
    "preprocess='MS'\n",
    "metric='RuLSIF'\n",
    "\n",
    "total_counts=np.zeros(4)\n",
    "denom = numer = 0\n",
    "\n",
    "time_threshold=30\n",
    "score_threshold=0.3\n",
    "\n",
    "for activity_folder in glob.glob(\"./outputs/{}/{}/*\".format(data_name, preprocess)):\n",
    "    # one type of pairs\n",
    "    activity_pair=activity_folder.split(\"/\")[-1]\n",
    "    print(activity_pair)\n",
    "    pair_counts=np.zeros(4) # TP, FP, TN, FN\n",
    "\n",
    "    for episode_folder in glob.glob(\"{}/*\".format(activity_folder)):\n",
    "        # print(episode_folder)\n",
    "        denom+=1\n",
    "        eps_order=int(episode_folder.split(\"/\")[-1].split(\"_\")[0])\n",
    "        eps, point=episodes[eps_order], trs[eps_order]\n",
    "        scores=np.load(\"{}/{}/scores.npy\".format(episode_folder, metric))\n",
    "\n",
    "        positives=[i for i in range(len(scores)) if scores[i]>score_threshold]\n",
    "\n",
    "        peaks=[]\n",
    "        prevPeakTimestamp=-1\n",
    "        for p in positives:\n",
    "            if prevPeakTimestamp==-1 or float(eps[p][2])-prevPeakTimestamp>=time_threshold*2:\n",
    "                peaks.append(p)\n",
    "                prevPeakTimestamp=float(eps[p][2])\n",
    "\n",
    "        numer+=len(peaks)\n",
    "        ttimestamp=float(eps[point][2])\n",
    "\n",
    "        for i in range(len(scores)):\n",
    "            if i in positives:\n",
    "                if i==point:\n",
    "                    pair_counts[0]+=1\n",
    "                else:\n",
    "                    # timestamp_b=float(eps[i-1][2])\n",
    "                    timestamp_a=float(eps[i][2])\n",
    "                    # if abs(ttimestamp-timestamp_b)<threshold or abs(ttimestamp-timestamp_a)<threshold:\n",
    "                    if abs(ttimestamp-timestamp_a)<time_threshold:\n",
    "                        pair_counts[0]+=1\n",
    "                    else:\n",
    "                        pair_counts[1]+=1\n",
    "            else:\n",
    "                if i==point:\n",
    "                    pair_counts[3]+=1\n",
    "                else:\n",
    "                    pair_counts[2]+=1\n",
    "    TPR_=pair_counts[0]/(pair_counts[0]+pair_counts[3])\n",
    "    FPR_=pair_counts[1]/(pair_counts[1]+pair_counts[2])\n",
    "    print(\"Avg. TPR and FPR: ({}, {})\".format(TPR_, FPR_))\n",
    "\n",
    "    total_counts+=pair_counts\n",
    "\n",
    "TPR=total_counts[0]/(total_counts[0]+total_counts[3])\n",
    "FPR=total_counts[1]/(total_counts[1]+total_counts[2])\n",
    "print(\"Total Avg. TPR and FPR: ({}, {})\".format(TPR, FPR))\n",
    "\n",
    "print(numer/denom)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import packages\n",
    "\"\"\"\n",
    "import os, glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, random\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "import path, sys, re, time\n",
    "from collections import Counter\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import custom packages\n",
    "\"\"\"\n",
    "from module_.info.testbed_info import d_files, g_files, c_files, p_files\n",
    "from module_.info.config import config, feature_name\n",
    "from module_.readText import create_episodes, time_correction\n",
    "from module_.featureExtraction import feature_extraction\n",
    "from module_.changePointDetection import change_point_detection\n",
    "# from module_.evaluation import evaluation_\n",
    "# from module_.analysis import neighbor_events as ne\n",
    "# from module_.helper.labeling import feature_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testbed (Seminar, multi-resident, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load raw files\n",
    "\"\"\"\n",
    "dir_=\"dataset/testbed/discrete/\"\n",
    "task_dict={\n",
    "    0:  [np.load(dir_+file_name) for file_name in g_files.keys()],\n",
    "    1:  [np.load(dir_+file_name) for file_name in d_files.keys()],\n",
    "    2:  [np.load(dir_+file_name) for file_name in c_files.keys()],\n",
    "    3:  [np.load(dir_+file_name) for file_name in p_files.keys()]\n",
    "}\n",
    "name_dict={\n",
    "    0: 'G', 1: 'D', 2: 'C', 3: 'P'\n",
    "}\n",
    "\n",
    "episodes, trs, tags = create_episodes(task_dict, name_dict)\n",
    "episodes=[time_correction(eps, trs[i]) for i, eps in enumerate(episodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"make combinations\n",
    "    1. pick one group type\n",
    "    2. pick an activity stream from the group\n",
    "    3. pick another group type w/o type 1.\n",
    "    4. pick an activity stream from the group\n",
    "\"\"\"\n",
    "data_name='testbed'\n",
    "metric='SEP'\n",
    "\n",
    "for i, eps in enumerate(episodes):\n",
    "    pairname=tags[i][0]+tags[i][2]\n",
    "    print(i, tags[i])\n",
    "    sensor_list=sorted(set(eps[:,0]))\n",
    "    features=feature_extraction(eps, data_name, sensor_list)\n",
    "    scores=change_point_detection(features, i, pairname, data_name=data_name, metric=metric, save=True)\n",
    "    scores=np.array(scores)\n",
    "    scores[scores<0]=0\n",
    "\n",
    "    peak, _ =find_peaks(scores)\n",
    "    positive=[i for i in peak if scores[i]>0.3]\n",
    "    # positive=[i for i in range(len(scores)) if scores[i]>0.45]\n",
    "    \n",
    "###\n",
    "    plt.title(\"{}-{}\".format(tags[i], i))\n",
    "    plt.ylabel('score')\n",
    "    plt.xlabel('event')\n",
    "    plt.ylim(0,0.7)\n",
    "    plt.bar(range(len(eps)), scores)\n",
    "    plt.plot(positive, np.array(scores)[positive], 'bx', label='peak')\n",
    "    plt.axhline(y=0.45, linestyle=':', color='r', label='threshold')\n",
    "    plt.axvline(x=trs[i], linestyle=':', color='g', label='transition')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"./outputs/{}/{}/{}/{}/graph.png\".format(data_name, metric, pairname, i))\n",
    "    plt.clf()\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    hh101 Evaluation\n",
    "    - load scores\n",
    "\"\"\"\n",
    "total_counts=np.zeros(4)\n",
    "denom = numer = 0\n",
    "for activity_folder in glob.glob(\"./outputs/{}/{}/*\".format(data_name, metric)):\n",
    "    # one type of pairs\n",
    "    activity_pair=activity_folder.split(\"/\")[-1]\n",
    "    print(activity_pair)\n",
    "    pair_counts=np.zeros(4) # TP, FP, TN, FN\n",
    "\n",
    "    for episode_folder in glob.glob(\"{}/*\".format(activity_folder)):\n",
    "        denom+=1\n",
    "        eps_order=int(episode_folder.split(\"/\")[-1])\n",
    "        eps, point=episodes[eps_order], trs[eps_order]\n",
    "        scores=np.load(\"{}/scores.npy\".format(episode_folder))\n",
    "\n",
    "        peaks, _ = find_peaks(scores)\n",
    "        positives=[i for i in peaks if scores[i]>0.1]\n",
    "        numer+=len(positives)\n",
    "        # positives=[i for i in range(len(scores)) if scores[i]>0.3]\n",
    "        ttimestamp=float(eps[point][2])\n",
    "\n",
    "        for i in range(len(scores)):\n",
    "            if i in positives:\n",
    "                if i==point:\n",
    "                    pair_counts[0]+=1\n",
    "                else:\n",
    "                    timestamp_b=float(eps[i-1][2])\n",
    "                    timestamp_a=float(eps[i][2])\n",
    "                    if abs(ttimestamp-timestamp_b)<30 or abs(ttimestamp-timestamp_a)<30:\n",
    "                        pair_counts[0]+=1\n",
    "                    else:\n",
    "                        pair_counts[1]+=1\n",
    "            else:\n",
    "                if i==point:\n",
    "                    pair_counts[3]+=1\n",
    "                else:\n",
    "                    pair_counts[2]+=1\n",
    "    TPR_=pair_counts[0]/(pair_counts[0]+pair_counts[3])\n",
    "    FPR_=pair_counts[1]/(pair_counts[1]+pair_counts[2])\n",
    "    print(\"Avg. TPR and FPR: ({}, {})\".format(TPR_, FPR_))\n",
    "\n",
    "    total_counts+=pair_counts\n",
    "\n",
    "TPR=total_counts[0]/(total_counts[0]+total_counts[3])\n",
    "FPR=total_counts[1]/(total_counts[1]+total_counts[2])\n",
    "print(\"Total Avg. TPR and FPR: ({}, {})\".format(TPR, FPR))\n",
    "\n",
    "print(numer/denom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GC\n",
      "GP\n",
      "PG\n",
      "PD\n",
      "DG\n",
      "CD\n",
      "CG\n",
      "PC\n",
      "DC\n",
      "CP\n",
      "DP\n",
      "GD\n"
     ]
    }
   ],
   "source": [
    "data_name='testbed'\n",
    "metric='SEP'\n",
    "for activity_folder in glob.glob(\"./outputs/{}/{}/*\".format(data_name, metric)):\n",
    "    activity_pair=activity_folder.split(\"/\")[-1]\n",
    "    print(activity_pair)\n",
    "\n",
    "    for episode_folder in glob.glob(\"{}/*\".format(activity_folder)):\n",
    "        eps_order=int(episode_folder.split(\"/\")[-1])\n",
    "        eps, point=episodes[eps_order], trs[eps_order]\n",
    "        sensor_list=sorted(set(eps[:,0]))\n",
    "        features=feature_extraction(eps, data_name, sensor_list)\n",
    "        features=np.array(features)\n",
    "        scores=np.load(\"{}/scores.npy\".format(episode_folder))\n",
    "        lambdas=np.load(\"{}/lambdas.npy\".format(episode_folder))\n",
    "        sigmas=np.load(\"{}/sigmas.npy\".format(episode_folder))\n",
    "        thetas=np.load(\"{}/thetas.npy\".format(episode_folder))\n",
    "\n",
    "        peaks, _ = find_peaks(scores)\n",
    "        positives=[p for p in peaks if scores[p]>0.1]\n",
    "        \n",
    "        ttimestamp=float(eps[point][2])\n",
    "        true_positives=[p for p in positives if abs(ttimestamp-float(eps[p][2]))<=30]\n",
    "        false_positives=[p for p in positives if p not in true_positives]\n",
    "        \n",
    "        # creating window of the latest event\n",
    "        events_true_positives=[]\n",
    "        for p in true_positives:\n",
    "            low_bound=p-30+1\n",
    "            if low_bound<0:\n",
    "                repeat=np.array([0 for _ in range(30-p-1)])\n",
    "                window=np.concatenate((repeat, eps[:p+1]), axis=0)\n",
    "            else:\n",
    "                window=eps[low_bound:p+1,:]\n",
    "            window=np.concatenate((window, np.array([eps[min(len(eps)-1,p+1)], eps[min(len(eps)-1,p+2)]])), axis=0)\n",
    "            events_true_positives.append(window)\n",
    "        \n",
    "        events_false_positives=[]\n",
    "        for p in false_positives:\n",
    "            low_bound=p-30+1\n",
    "            if low_bound<0:\n",
    "                repeat=np.array([eps[0] for _ in range(30-p-1)])\n",
    "                window=np.concatenate((repeat, eps[:p+1]), axis=0)\n",
    "            else:\n",
    "                window=eps[low_bound:p+1,:]\n",
    "            window=np.concatenate((window, np.array([eps[min(len(eps)-1,p+1)], eps[min(len(eps)-1,p+2)]])), axis=0)\n",
    "            events_false_positives.append(window)\n",
    "\n",
    "        # events_true_positives=[eps[max(0, p-30):min(len(eps)-1, p+3)] for p in true_positives]\n",
    "        # events_false_positives=[eps[max(0, p-30):min(len(eps)-1, p+3)] for p in false_positives]\n",
    "\n",
    "        features_true_positives=[np.array(features)[[max(0,p-1),p,min(len(features)-1,p+1),min(len(features)-1,p+2)]] for p in true_positives]\n",
    "        features_false_positives=[np.array(features)[[max(0,p-1),p,min(len(features)-1,p+1),min(len(features)-1,p+2)]] for p in false_positives]\n",
    "\n",
    "        parameters_true_positives=[[lambdas[p], sigmas[p][0], sigmas[p][1]] for p in true_positives]\n",
    "        parameters_false_positives=[[lambdas[p], sigmas[p][0], sigmas[p][1]] for p in false_positives]\n",
    "\n",
    "        positive_folder=\"{}/positive\".format(episode_folder)\n",
    "        true_folder=\"{}/true\".format(positive_folder)\n",
    "        false_folder=\"{}/false\".format(positive_folder)\n",
    "\n",
    "        if not os.path.exists(positive_folder):\n",
    "            os.mkdir(positive_folder)\n",
    "        if not os.path.exists(true_folder):\n",
    "            os.mkdir(true_folder)\n",
    "        if not os.path.exists(false_folder):\n",
    "            os.mkdir(false_folder)\n",
    "\n",
    "        np.save(\"{}/events.npy\".format(true_folder), events_true_positives)\n",
    "        np.save(\"{}/features.npy\".format(true_folder), features_true_positives)\n",
    "        np.save(\"{}/parameters.npy\".format(true_folder), parameters_true_positives)\n",
    "\n",
    "        np.save(\"{}/events.npy\".format(false_folder), events_false_positives)\n",
    "        np.save(\"{}/features.npy\".format(false_folder), features_false_positives)\n",
    "        np.save(\"{}/parameters.npy\".format(false_folder), parameters_false_positives)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
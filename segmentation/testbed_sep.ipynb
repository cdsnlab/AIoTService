{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "import packages\n",
    "\"\"\"\n",
    "import os, glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, random\n",
    "import datetime as dt\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "import path, sys, re, time\n",
    "from collections import Counter\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.signal import find_peaks"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "import custom packages\n",
    "\"\"\"\n",
    "# from module_.info.testbed_info import d_files, g_files, c_files, p_files\n",
    "from module_.info.testbed_info import activityfiles_new\n",
    "from module_.info.config import config, feature_name\n",
    "from module_.readText import create_episodes, time_correction\n",
    "from module_.featureExtraction import feature_extraction\n",
    "from module_.changePointDetection import change_point_detection\n",
    "# from module_.evaluation import evaluation_\n",
    "# from module_.analysis import neighbor_events as ne\n",
    "# from module_.helper.labeling import feature_label"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testbed (Seminar, multi-resident, episodes)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "load raw files\n",
    "\"\"\"\n",
    "dir_=\"dataset/testbed/npy/seminar\"\n",
    "task_dict={i:[np.load(\"{}/{}\".format(dir_, name)) for name in v] for i, v in enumerate(activityfiles_new.values())}\n",
    "initial_dict={i:k[0] for i, k in enumerate(activityfiles_new.keys())}\n",
    "label_dict={k[0]:k for k in activityfiles_new.keys()}\n",
    "# task_dict={\n",
    "#     0:  [np.load(dir_+file_name) for file_name in g_files.keys()],\n",
    "#     1:  [np.load(dir_+file_name) for file_name in d_files.keys()],\n",
    "#     2:  [np.load(dir_+file_name) for file_name in c_files.keys()],\n",
    "#     3:  [np.load(dir_+file_name) for file_name in p_files.keys()]\n",
    "# }\n",
    "# name_dict={\n",
    "#     0: 'G', 1: 'D', 2: 'C', 3: 'P'\n",
    "# }\n",
    "\n",
    "episodes, trs, tags = create_episodes(task_dict, initial_dict)\n",
    "episodes=[time_correction(eps, trs[i]) for i, eps in enumerate(episodes)]"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"make combinations\n",
    "    1. pick one group type\n",
    "    2. pick an activity stream from the group\n",
    "    3. pick another group type w/o type 1.\n",
    "    4. pick an activity stream from the group\n",
    "\"\"\"\n",
    "data_name='testbed'\n",
    "metric='RuLSIF'\n",
    "\n",
    "for i, eps in enumerate(episodes):\n",
    "\n",
    "    pairname=\"{}-{}\".format(label_dict[tags[i][0]], label_dict[tags[i][2]])\n",
    "    print(i, tags[i])\n",
    "    sensor_list=sorted(set(eps[:,0]))\n",
    "    features=feature_extraction(eps, data_name, sensor_list)\n",
    "    scores=change_point_detection(features, i, pairname, data_name=data_name, metric=metric, save=True)\n",
    "\n",
    "    # print(eps[120:150])\n",
    "    # scores=np.array(scores)\n",
    "\n",
    "    # scores=[scores[max(0, si-1)]+scores[max(0, si-2)] for si in range(len(scores))]\n",
    "    # scores[scores<0]=0\n",
    "\n",
    "    # peak, _ =find_peaks(scores)\n",
    "    # positive=[i for i in peak if scores[i]>0.1]\n",
    "    # positive=[i for i in range(len(scores)) if scores[i]>0.45]\n",
    "    \n",
    "###\n",
    "    plt.title(\"{}-{}\".format(tags[i], i))\n",
    "    plt.ylabel('score')\n",
    "    plt.xlabel('event')\n",
    "    plt.ylim(0,0.7)\n",
    "    plt.bar(range(len(eps)), scores)\n",
    "    # plt.plot(positive, np.array(scores)[positive], 'bx', label='peak')\n",
    "    plt.axhline(y=0.1, linestyle=':', color='r', label='threshold')\n",
    "    plt.axvline(x=trs[i], linestyle=':', color='g', label='transition')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"./outputs/{}/{}/{}/{}/graph.png\".format(data_name, metric, pairname, i))\n",
    "\n",
    "    # break\n",
    "    plt.clf()\n",
    "    # break\n",
    "###"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "\"\"\"\n",
    "    hh101 Evaluation\n",
    "    - load scores\n",
    "\"\"\"\n",
    "\n",
    "data_name='testbed'\n",
    "metric='RuLSIF'\n",
    "\n",
    "total_counts=np.zeros(4)\n",
    "denom = numer = 0\n",
    "for activity_folder in glob.glob(\"./outputs/{}/{}/*\".format(data_name, metric)):\n",
    "    # if \"ETC\" in activity_folder:\n",
    "    #     continue\n",
    "    # one type of pairs\n",
    "    activity_pair=activity_folder.split(\"/\")[-1]\n",
    "    print(activity_pair)\n",
    "    pair_counts=np.zeros(4) # TP, FP, TN, FN\n",
    "\n",
    "    for episode_folder in glob.glob(\"{}/*\".format(activity_folder)):\n",
    "        denom+=1\n",
    "        eps_order=int(episode_folder.split(\"/\")[-1])\n",
    "        eps, point=episodes[eps_order], trs[eps_order]\n",
    "        scores=np.load(\"{}/scores.npy\".format(episode_folder))\n",
    "\n",
    "        # peaks, _ = find_peaks(scores)\n",
    "        positives=[i for i in range(len(scores)) if scores[i]>0.1]\n",
    "        numer+=len(positives)\n",
    "        # positives=[i for i in range(len(scores)) if scores[i]>0.3]\n",
    "        ttimestamp=float(eps[point][2])\n",
    "\n",
    "        for i in range(len(scores)):\n",
    "            if i in positives:\n",
    "                if i==point:\n",
    "                    pair_counts[0]+=1\n",
    "                else:\n",
    "                    timestamp_b=float(eps[i-1][2])\n",
    "                    timestamp_a=float(eps[i][2])\n",
    "                    if abs(ttimestamp-timestamp_b)<30 or abs(ttimestamp-timestamp_a)<30:\n",
    "                        pair_counts[0]+=1\n",
    "                    else:\n",
    "                        pair_counts[1]+=1\n",
    "            else:\n",
    "                if i==point:\n",
    "                    pair_counts[3]+=1\n",
    "                else:\n",
    "                    pair_counts[2]+=1\n",
    "    TPR_=pair_counts[0]/(pair_counts[0]+pair_counts[3])\n",
    "    FPR_=pair_counts[1]/(pair_counts[1]+pair_counts[2])\n",
    "    print(\"Avg. TPR and FPR: ({}, {})\".format(TPR_, FPR_))\n",
    "\n",
    "    total_counts+=pair_counts\n",
    "\n",
    "TPR=total_counts[0]/(total_counts[0]+total_counts[3])\n",
    "FPR=total_counts[1]/(total_counts[1]+total_counts[2])\n",
    "print(\"Total Avg. TPR and FPR: ({}, {})\".format(TPR, FPR))\n",
    "\n",
    "print(numer/denom)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Seminar-TechnicalDiscussion\n",
      "Avg. TPR and FPR: (0.7241379310344828, 0.2670358776787864)\n",
      "Seminar-Chatting\n",
      "Avg. TPR and FPR: (0.75, 0.3005390835579515)\n",
      "TechnicalDiscussion-GroupStudy\n",
      "Avg. TPR and FPR: (0.8275862068965517, 0.2647216274089936)\n",
      "Chatting-GroupStudy\n",
      "Avg. TPR and FPR: (0.7272727272727273, 0.28621632174931666)\n",
      "GroupStudy-TechnicalDiscussion\n",
      "Avg. TPR and FPR: (0.7407407407407407, 0.26003210272873195)\n",
      "Chatting-TechnicalDiscussion\n",
      "Avg. TPR and FPR: (0.75, 0.29137276180141075)\n",
      "GroupStudy-Seminar\n",
      "Avg. TPR and FPR: (0.5555555555555556, 0.2805802835476426)\n",
      "Chatting-Seminar\n",
      "Avg. TPR and FPR: (0.5555555555555556, 0.30482897384305835)\n",
      "TechnicalDiscussion-Seminar\n",
      "Avg. TPR and FPR: (0.6470588235294118, 0.2792316926770708)\n",
      "GroupStudy-Chatting\n",
      "Avg. TPR and FPR: (0.7307692307692307, 0.29487680876026595)\n",
      "Seminar-GroupStudy\n",
      "Avg. TPR and FPR: (0.6666666666666666, 0.2689131152956723)\n",
      "TechnicalDiscussion-Chatting\n",
      "Avg. TPR and FPR: (0.7666666666666667, 0.2893593919652552)\n",
      "Total Avg. TPR and FPR: (0.7166666666666667, 0.2811119384462646)\n",
      "106.86111111111111\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "data_name='testbed'\n",
    "metric='RuLSIF'\n",
    "\n",
    "# total_counts=np.zeros(4)\n",
    "# denom = numer = 0\n",
    "for activity_folder in glob.glob(\"./outputs/{}/{}/*\".format(data_name, metric)):\n",
    "\n",
    "    # one type of pairs\n",
    "    activity_pair=activity_folder.split(\"/\")[-1]\n",
    "    print(activity_pair)\n",
    "    pair_counts=np.zeros(4) # TP, FP, TN, FN\n",
    "\n",
    "    for episode_folder in glob.glob(\"{}/*\".format(activity_folder)):\n",
    "        # denom+=1\n",
    "        eps_order=int(episode_folder.split(\"/\")[-1])\n",
    "        eps, point=episodes[eps_order], trs[eps_order]\n",
    "        scores=np.load(\"{}/scores.npy\".format(episode_folder))\n",
    "        lambdas=np.load(\"{}/lambdas.npy\".format(episode_folder))\n",
    "        sigmas=np.load(\"{}/sigmas.npy\".format(episode_folder))\n",
    "        thetas=np.load(\"{}/thetas.npy\".format(episode_folder))\n",
    "        scores[scores<0]=0\n",
    "        print('transition', point)\n",
    "        # plt.plot(range(len(scores)), scores)\n",
    "        # plt.axvline(x=point, color='r')\n",
    "\n",
    "        peak = [p for p in range(len(scores)) if scores[p]>0.5]\n",
    "        nonpeak = [p for p in range(len(scores)) if scores[p]==0]\n",
    "        print(len(peak))\n",
    "        print(len(nonpeak))\n",
    "\n",
    "        sensor_list=sorted(set(eps[:,0]))\n",
    "        features=feature_extraction(eps, data_name, sensor_list)\n",
    "\n",
    "        for p in nonpeak[49:56]:\n",
    "            before=[features[p-1], features[p]]\n",
    "            after=[features[p], features[p+1]]\n",
    "            # print(scores[p], lambdas[p], sigmas[p], thetas[p])\n",
    "            print(np.square(distance_matrix(before, before)).ravel())\n",
    "            print(np.square(distance_matrix(before, after)).ravel())\n",
    "            print(eps[p-31:p+2])\n",
    "        # print(max(scores), min(scores))\n",
    "        break\n",
    "\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Seminar-TechnicalDiscussion\n",
      "transition 176\n",
      "7\n",
      "98\n",
      "[0.         1.01777784 1.01777784 0.        ]\n",
      "[1.01777784 1.00137935 0.         0.02001349]\n",
      "[]\n",
      "[0.         1.53821511 1.53821511 0.        ]\n",
      "[1.53821511 2.07464059 0.         1.22029631]\n",
      "[]\n",
      "[0.        1.1117412 1.1117412 0.       ]\n",
      "[1.1117412  1.00412606 0.         0.11510909]\n",
      "[]\n",
      "[0.         0.11510909 0.11510909 0.        ]\n",
      "[0.11510909 0.12067527 0.         0.00540895]\n",
      "[]\n",
      "[0.         1.36225654 1.36225654 0.        ]\n",
      "[1.36225654 1.00943169 0.         0.36677378]\n",
      "[]\n",
      "[0.         0.36677378 0.36677378 0.        ]\n",
      "[0.36677378 0.07807735 0.         0.11111777]\n",
      "[]\n",
      "[0.         0.11111777 0.11111777 0.        ]\n",
      "[0.11111777 0.45597685 0.         0.16685253]\n",
      "[]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Positive Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_name='testbed'\n",
    "metric='SEP'\n",
    "for activity_folder in glob.glob(\"./outputs/{}/{}/NOMOTION/*\".format(data_name, metric)):\n",
    "    activity_pair=activity_folder.split(\"/\")[-1]\n",
    "    print(activity_pair)\n",
    "\n",
    "    for episode_folder in glob.glob(\"{}/*\".format(activity_folder)):\n",
    "        eps_order=int(episode_folder.split(\"/\")[-1])\n",
    "        eps, point=episodes[eps_order], trs[eps_order]\n",
    "        sensor_list=sorted(set(eps[:,0]))\n",
    "        features=feature_extraction(eps, data_name, sensor_list)\n",
    "        features=np.array(features)\n",
    "        scores=np.load(\"{}/scores.npy\".format(episode_folder))\n",
    "        lambdas=np.load(\"{}/lambdas.npy\".format(episode_folder))\n",
    "        sigmas=np.load(\"{}/sigmas.npy\".format(episode_folder))\n",
    "        thetas=np.load(\"{}/thetas.npy\".format(episode_folder))\n",
    "\n",
    "        peaks, _ = find_peaks(scores)\n",
    "        positives=[p for p in peaks if scores[p]>0.1]\n",
    "        \n",
    "        ttimestamp=float(eps[point][2])\n",
    "        true_positives=[p for p in positives if abs(ttimestamp-float(eps[p][2]))<=30]\n",
    "        false_positives=[p for p in positives if p not in true_positives]\n",
    "        \n",
    "        # creating window of the latest event\n",
    "        events_true_positives=[]\n",
    "        for p in true_positives:\n",
    "            bucket=[]\n",
    "            idx=p-30\n",
    "            while idx!=p:\n",
    "                bucket.append(eps[max(0, idx),:])\n",
    "                idx+=1\n",
    "            bucket.append(eps[p,:])\n",
    "            bucket.append(eps[min(len(eps)-1,p+1)])\n",
    "            bucket.append(eps[min(len(eps)-1,p+2)])\n",
    "            events_true_positives.append(np.array(bucket))\n",
    "        \n",
    "        events_false_positives=[]\n",
    "        for p in false_positives:\n",
    "            bucket=[]\n",
    "            idx=p-30\n",
    "            while idx!=p:\n",
    "                bucket.append(eps[max(0, idx),:])\n",
    "                idx+=1\n",
    "            bucket.append(eps[p,:])\n",
    "            bucket.append(eps[min(len(eps)-1,p+1)])\n",
    "            bucket.append(eps[min(len(eps)-1,p+2)])\n",
    "            events_false_positives.append(np.array(bucket))\n",
    "\n",
    "        features_true_positives=[np.array(features)[[max(0,p-1),p,min(len(features)-1,p+1),min(len(features)-1,p+2)]] for p in true_positives]\n",
    "        features_false_positives=[np.array(features)[[max(0,p-1),p,min(len(features)-1,p+1),min(len(features)-1,p+2)]] for p in false_positives]\n",
    "\n",
    "        parameters_true_positives=[[lambdas[p], sigmas[p][0], sigmas[p][1]] for p in true_positives]\n",
    "        parameters_false_positives=[[lambdas[p], sigmas[p][0], sigmas[p][1]] for p in false_positives]\n",
    "\n",
    "        scores_true_positives=[scores[p] for p in true_positives]\n",
    "        scores_false_positives=[scores[p] for p in false_positives]\n",
    "\n",
    "        positive_folder=\"{}/positive\".format(episode_folder)\n",
    "        true_folder=\"{}/true\".format(positive_folder)\n",
    "        false_folder=\"{}/false\".format(positive_folder)\n",
    "\n",
    "        if not os.path.exists(positive_folder):\n",
    "            os.mkdir(positive_folder)\n",
    "        if not os.path.exists(true_folder):\n",
    "            os.mkdir(true_folder)\n",
    "        if not os.path.exists(false_folder):\n",
    "            os.mkdir(false_folder)\n",
    "\n",
    "        np.save(\"{}/events.npy\".format(true_folder), events_true_positives)\n",
    "        np.save(\"{}/features.npy\".format(true_folder), features_true_positives)\n",
    "        np.save(\"{}/parameters.npy\".format(true_folder), parameters_true_positives)\n",
    "        np.save(\"{}/scores.npy\".format(true_folder), scores_true_positives)\n",
    "\n",
    "        np.save(\"{}/events.npy\".format(false_folder), events_false_positives)\n",
    "        np.save(\"{}/features.npy\".format(false_folder), features_false_positives)\n",
    "        np.save(\"{}/parameters.npy\".format(false_folder), parameters_false_positives)\n",
    "        np.save(\"{}/scores.npy\".format(false_folder), scores_false_positives)\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# False Positive Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_name='testbed'\n",
    "metric='SEP'\n",
    "\n",
    "for afolder in glob.glob(\"./outputs/testbed/SEP/NOMOTION/*\"):\n",
    "    print(afolder)\n",
    "    for efolder in glob.glob(\"{}/*\".format(afolder)):\n",
    "        fpevents=np.load(\"{}/positive/false/events.npy\".format(efolder))\n",
    "        fpfeatures=np.load(\"{}/positive/false/features.npy\".format(efolder))\n",
    "        fpparameters=np.load(\"{}/positive/false/parameters.npy\".format(efolder))\n",
    "        fpscores=np.load(\"{}/positive/false/scores.npy\".format(efolder))\n",
    "\n",
    "        order=9\n",
    "        # print(dt.datetime.fromtimestamp(float(fpevents[order][-3,2])))\n",
    "        # print(fpevents.shape, fpfeatures.shape, fpparameters.shape)\n",
    "        \n",
    "        print(fpscores[order], fpparameters[order])\n",
    "        # print(np.round(fpfeatures[order],2))\n",
    "        # print(fpevents[order])\n",
    "\n",
    "        print(np.array([item for item in fpevents[order] if item[1]=='true']))\n",
    "\n",
    "\n",
    "        break\n",
    "    break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# True Positive Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_name='testbed'\n",
    "metric='SEP'\n",
    "\n",
    "for afolder in glob.glob(\"./outputs/testbed/SEP/NOMOTION/*\"):\n",
    "    pairname=afolder.split(\"/\")[-1]\n",
    "    print(afolder)\n",
    "    for efolder in glob.glob(\"{}/*\".format(afolder)):\n",
    "        epsnumber=efolder.split(\"/\")[-1]\n",
    "        print(efolder)\n",
    "        tpevents=np.load(\"{}/positive/true/events.npy\".format(efolder))\n",
    "        tpfeatures=np.load(\"{}/positive/true/features.npy\".format(efolder))\n",
    "        tpparameters=np.load(\"{}/positive/true/parameters.npy\".format(efolder))\n",
    "        tpscores=np.load(\"{}/positive/true/scores.npy\".format(efolder))\n",
    "        \n",
    "        if tpevents.shape[0]==0:\n",
    "            continue\n",
    "        \n",
    "        for order in range(tpevents.shape[0]):\n",
    "            # true_events=np.array([item for item in tpevents[order] if item[1]=='true'])\n",
    "\n",
    "            target=tpevents[order]\n",
    "\n",
    "            min_timestamp=min([float(event[2]) for event in target])\n",
    "            sensor_timestamp={item:[] for item in set(target[:,0])}\n",
    "            for event in target:\n",
    "                sensor_timestamp[event[0]].append(float(event[2])-min_timestamp)\n",
    "\n",
    "            plt.title(\"True-Positive-{}\".format(order))\n",
    "            plt.xlabel(\"timestamp\")\n",
    "            yintv=0.01\n",
    "            for k, v in sensor_timestamp.items():\n",
    "                plt.plot(v, [yintv for _ in range(len(v))], 'o', label=k)\n",
    "                for time_ in v:\n",
    "                    plt.axvline(x=time_, linestyle=\":\")\n",
    "                yintv+=0.01\n",
    "            plt.legend()\n",
    "            plt.savefig(\"./analysis/{}/{}/positive/true/NOMOTION/{}_{}_{}.png\".format(data_name, metric, pairname, epsnumber, order))\n",
    "            plt.clf()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# False Positive Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_name='testbed'\n",
    "metric='SEP'\n",
    "\n",
    "for afolder in glob.glob(\"./outputs/testbed/SEP/NOMOTION/*\"):\n",
    "    pairname=afolder.split(\"/\")[-1]\n",
    "    print(afolder)\n",
    "    for efolder in glob.glob(\"{}/*\".format(afolder)):\n",
    "        epsnumber=efolder.split(\"/\")[-1]\n",
    "        print(efolder)\n",
    "        tpevents=np.load(\"{}/positive/false/events.npy\".format(efolder))\n",
    "        tpfeatures=np.load(\"{}/positive/false/features.npy\".format(efolder))\n",
    "        tpparameters=np.load(\"{}/positive/false/parameters.npy\".format(efolder))\n",
    "        tpscores=np.load(\"{}/positive/false/scores.npy\".format(efolder))\n",
    "        \n",
    "        if tpevents.shape[0]==0:\n",
    "            continue\n",
    "        \n",
    "        for order in range(tpevents.shape[0]):\n",
    "            # true_events=np.array([item for item in tpevents[order] if item[1]=='true'])\n",
    "\n",
    "            target=tpevents[order]\n",
    "\n",
    "            min_timestamp=min([float(event[2]) for event in target])\n",
    "            sensor_timestamp={item:[] for item in set(target[:,0])}\n",
    "            for event in target:\n",
    "                sensor_timestamp[event[0]].append(float(event[2])-min_timestamp)\n",
    "\n",
    "            plt.title(\"False-Positive-{}\".format(order))\n",
    "            plt.xlabel(\"timestamp\")\n",
    "            yintv=0.01\n",
    "            for k, v in sensor_timestamp.items():\n",
    "                plt.plot(v, [yintv for _ in range(len(v))], 'o', label=k)\n",
    "                for time_ in v:\n",
    "                    plt.axvline(x=time_, linestyle=\":\")\n",
    "                yintv+=0.01\n",
    "            plt.legend()\n",
    "            plt.savefig(\"./analysis/{}/{}/positive/false/NOMOTION/{}_{}_{}.png\".format(data_name, metric, pairname, epsnumber, order))\n",
    "            plt.clf()\n",
    "        break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import packages\n",
    "\"\"\"\n",
    "import os, glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, random\n",
    "import datetime as dt\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "import path, sys, re, time\n",
    "from collections import Counter\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import custom packages\n",
    "\"\"\"\n",
    "# from module_.info.testbed_info import d_files, g_files, c_files, p_files\n",
    "from module_.info.testbed_info import activityfiles_new\n",
    "from module_.info.config import config, feature_name\n",
    "from module_.readText import create_episodes, time_correction\n",
    "from module_.featureExtraction import feature_extraction\n",
    "from module_.changePointDetection import change_point_detection\n",
    "# from module_.evaluation import evaluation_\n",
    "# from module_.analysis import neighbor_events as ne\n",
    "# from module_.helper.labeling import feature_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testbed (Seminar, multi-resident, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load raw files\n",
    "\"\"\"\n",
    "dir_=\"dataset/testbed/npy/seminar\"\n",
    "task_dict={i:[np.load(\"{}/{}\".format(dir_, name)) for name in v] for i, v in enumerate(activityfiles_new.values())}\n",
    "initial_dict={i:k[0] for i, k in enumerate(activityfiles_new.keys())}\n",
    "label_dict={k[0]:k for k in activityfiles_new.keys()}\n",
    "# task_dict={\n",
    "#     0:  [np.load(dir_+file_name) for file_name in g_files.keys()],\n",
    "#     1:  [np.load(dir_+file_name) for file_name in d_files.keys()],\n",
    "#     2:  [np.load(dir_+file_name) for file_name in c_files.keys()],\n",
    "#     3:  [np.load(dir_+file_name) for file_name in p_files.keys()]\n",
    "# }\n",
    "# name_dict={\n",
    "#     0: 'G', 1: 'D', 2: 'C', 3: 'P'\n",
    "# }\n",
    "\n",
    "episodes, trs, tags = create_episodes(task_dict, initial_dict)\n",
    "episodes=[time_correction(eps, trs[i]) for i, eps in enumerate(episodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"make combinations\n",
    "    1. pick one group type\n",
    "    2. pick an activity stream from the group\n",
    "    3. pick another group type w/o type 1.\n",
    "    4. pick an activity stream from the group\n",
    "\"\"\"\n",
    "data_name='testbed'\n",
    "metric='SEP'\n",
    "\n",
    "for i, eps in enumerate(episodes):\n",
    "    pairname=\"{}-{}\".format(label_dict[tags[i][0]], label_dict[tags[i][2]])\n",
    "    print(i, tags[i])\n",
    "    sensor_list=sorted(set(eps[:,0]))\n",
    "    features=feature_extraction(eps, data_name, sensor_list)\n",
    "    scores=change_point_detection(features, i, pairname, data_name=data_name, metric=metric, save=True)\n",
    "    scores=np.array(scores)\n",
    "    scores[scores<0]=0\n",
    "\n",
    "    peak, _ =find_peaks(scores)\n",
    "    positive=[i for i in peak if scores[i]>0.1]\n",
    "    # positive=[i for i in range(len(scores)) if scores[i]>0.45]\n",
    "    \n",
    "###\n",
    "    plt.title(\"{}-{}\".format(tags[i], i))\n",
    "    plt.ylabel('score')\n",
    "    plt.xlabel('event')\n",
    "    plt.ylim(0,0.7)\n",
    "    plt.bar(range(len(eps)), scores)\n",
    "    # plt.plot(positive, np.array(scores)[positive], 'bx', label='peak')\n",
    "    plt.axhline(y=0.1, linestyle=':', color='r', label='threshold')\n",
    "    plt.axvline(x=trs[i], linestyle=':', color='g', label='transition')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"./outputs/{}/{}/{}/{}/graph.png\".format(data_name, metric, pairname, i))\n",
    "    plt.clf()\n",
    "    break\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    hh101 Evaluation\n",
    "    - load scores\n",
    "\"\"\"\n",
    "total_counts=np.zeros(4)\n",
    "denom = numer = 0\n",
    "for activity_folder in glob.glob(\"./outputs/{}/{}/NOMOTION/*\".format(data_name, metric)):\n",
    "    # one type of pairs\n",
    "    activity_pair=activity_folder.split(\"/\")[-1]\n",
    "    print(activity_pair)\n",
    "    pair_counts=np.zeros(4) # TP, FP, TN, FN\n",
    "\n",
    "    for episode_folder in glob.glob(\"{}/*\".format(activity_folder)):\n",
    "        denom+=1\n",
    "        eps_order=int(episode_folder.split(\"/\")[-1])\n",
    "        eps, point=episodes[eps_order], trs[eps_order]\n",
    "        scores=np.load(\"{}/scores.npy\".format(episode_folder))\n",
    "\n",
    "        peaks, _ = find_peaks(scores)\n",
    "        positives=[i for i in peaks if scores[i]>0.1]\n",
    "        numer+=len(positives)\n",
    "        # positives=[i for i in range(len(scores)) if scores[i]>0.3]\n",
    "        ttimestamp=float(eps[point][2])\n",
    "\n",
    "        for i in range(len(scores)):\n",
    "            if i in positives:\n",
    "                if i==point:\n",
    "                    pair_counts[0]+=1\n",
    "                else:\n",
    "                    timestamp_b=float(eps[i-1][2])\n",
    "                    timestamp_a=float(eps[i][2])\n",
    "                    if abs(ttimestamp-timestamp_b)<30 or abs(ttimestamp-timestamp_a)<30:\n",
    "                        pair_counts[0]+=1\n",
    "                    else:\n",
    "                        pair_counts[1]+=1\n",
    "            else:\n",
    "                if i==point:\n",
    "                    pair_counts[3]+=1\n",
    "                else:\n",
    "                    pair_counts[2]+=1\n",
    "    TPR_=pair_counts[0]/(pair_counts[0]+pair_counts[3])\n",
    "    FPR_=pair_counts[1]/(pair_counts[1]+pair_counts[2])\n",
    "    print(\"Avg. TPR and FPR: ({}, {})\".format(TPR_, FPR_))\n",
    "\n",
    "    total_counts+=pair_counts\n",
    "\n",
    "TPR=total_counts[0]/(total_counts[0]+total_counts[3])\n",
    "FPR=total_counts[1]/(total_counts[1]+total_counts[2])\n",
    "print(\"Total Avg. TPR and FPR: ({}, {})\".format(TPR, FPR))\n",
    "\n",
    "print(numer/denom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name='testbed'\n",
    "metric='SEP'\n",
    "for activity_folder in glob.glob(\"./outputs/{}/{}/NOMOTION/*\".format(data_name, metric)):\n",
    "    activity_pair=activity_folder.split(\"/\")[-1]\n",
    "    print(activity_pair)\n",
    "\n",
    "    for episode_folder in glob.glob(\"{}/*\".format(activity_folder)):\n",
    "        eps_order=int(episode_folder.split(\"/\")[-1])\n",
    "        eps, point=episodes[eps_order], trs[eps_order]\n",
    "        sensor_list=sorted(set(eps[:,0]))\n",
    "        features=feature_extraction(eps, data_name, sensor_list)\n",
    "        features=np.array(features)\n",
    "        scores=np.load(\"{}/scores.npy\".format(episode_folder))\n",
    "        lambdas=np.load(\"{}/lambdas.npy\".format(episode_folder))\n",
    "        sigmas=np.load(\"{}/sigmas.npy\".format(episode_folder))\n",
    "        thetas=np.load(\"{}/thetas.npy\".format(episode_folder))\n",
    "\n",
    "        peaks, _ = find_peaks(scores)\n",
    "        positives=[p for p in peaks if scores[p]>0.1]\n",
    "        \n",
    "        ttimestamp=float(eps[point][2])\n",
    "        true_positives=[p for p in positives if abs(ttimestamp-float(eps[p][2]))<=30]\n",
    "        false_positives=[p for p in positives if p not in true_positives]\n",
    "        \n",
    "        # creating window of the latest event\n",
    "        events_true_positives=[]\n",
    "        for p in true_positives:\n",
    "            bucket=[]\n",
    "            idx=p-30\n",
    "            while idx!=p:\n",
    "                bucket.append(eps[max(0, idx),:])\n",
    "                idx+=1\n",
    "            bucket.append(eps[p,:])\n",
    "            bucket.append(eps[min(len(eps)-1,p+1)])\n",
    "            bucket.append(eps[min(len(eps)-1,p+2)])\n",
    "            events_true_positives.append(np.array(bucket))\n",
    "        \n",
    "        events_false_positives=[]\n",
    "        for p in false_positives:\n",
    "            bucket=[]\n",
    "            idx=p-30\n",
    "            while idx!=p:\n",
    "                bucket.append(eps[max(0, idx),:])\n",
    "                idx+=1\n",
    "            bucket.append(eps[p,:])\n",
    "            bucket.append(eps[min(len(eps)-1,p+1)])\n",
    "            bucket.append(eps[min(len(eps)-1,p+2)])\n",
    "            events_false_positives.append(np.array(bucket))\n",
    "\n",
    "        features_true_positives=[np.array(features)[[max(0,p-1),p,min(len(features)-1,p+1),min(len(features)-1,p+2)]] for p in true_positives]\n",
    "        features_false_positives=[np.array(features)[[max(0,p-1),p,min(len(features)-1,p+1),min(len(features)-1,p+2)]] for p in false_positives]\n",
    "\n",
    "        parameters_true_positives=[[lambdas[p], sigmas[p][0], sigmas[p][1]] for p in true_positives]\n",
    "        parameters_false_positives=[[lambdas[p], sigmas[p][0], sigmas[p][1]] for p in false_positives]\n",
    "\n",
    "        scores_true_positives=[scores[p] for p in true_positives]\n",
    "        scores_false_positives=[scores[p] for p in false_positives]\n",
    "\n",
    "        positive_folder=\"{}/positive\".format(episode_folder)\n",
    "        true_folder=\"{}/true\".format(positive_folder)\n",
    "        false_folder=\"{}/false\".format(positive_folder)\n",
    "\n",
    "        if not os.path.exists(positive_folder):\n",
    "            os.mkdir(positive_folder)\n",
    "        if not os.path.exists(true_folder):\n",
    "            os.mkdir(true_folder)\n",
    "        if not os.path.exists(false_folder):\n",
    "            os.mkdir(false_folder)\n",
    "\n",
    "        np.save(\"{}/events.npy\".format(true_folder), events_true_positives)\n",
    "        np.save(\"{}/features.npy\".format(true_folder), features_true_positives)\n",
    "        np.save(\"{}/parameters.npy\".format(true_folder), parameters_true_positives)\n",
    "        np.save(\"{}/scores.npy\".format(true_folder), scores_true_positives)\n",
    "\n",
    "        np.save(\"{}/events.npy\".format(false_folder), events_false_positives)\n",
    "        np.save(\"{}/features.npy\".format(false_folder), features_false_positives)\n",
    "        np.save(\"{}/parameters.npy\".format(false_folder), parameters_false_positives)\n",
    "        np.save(\"{}/scores.npy\".format(false_folder), scores_false_positives)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# False Positive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name='testbed'\n",
    "metric='SEP'\n",
    "\n",
    "for afolder in glob.glob(\"./outputs/testbed/SEP/NOMOTION/*\"):\n",
    "    print(afolder)\n",
    "    for efolder in glob.glob(\"{}/*\".format(afolder)):\n",
    "        fpevents=np.load(\"{}/positive/false/events.npy\".format(efolder))\n",
    "        fpfeatures=np.load(\"{}/positive/false/features.npy\".format(efolder))\n",
    "        fpparameters=np.load(\"{}/positive/false/parameters.npy\".format(efolder))\n",
    "        fpscores=np.load(\"{}/positive/false/scores.npy\".format(efolder))\n",
    "\n",
    "        order=9\n",
    "        # print(dt.datetime.fromtimestamp(float(fpevents[order][-3,2])))\n",
    "        # print(fpevents.shape, fpfeatures.shape, fpparameters.shape)\n",
    "        \n",
    "        print(fpscores[order], fpparameters[order])\n",
    "        # print(np.round(fpfeatures[order],2))\n",
    "        # print(fpevents[order])\n",
    "\n",
    "        print(np.array([item for item in fpevents[order] if item[1]=='true']))\n",
    "\n",
    "\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# True Positive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name='testbed'\n",
    "metric='SEP'\n",
    "\n",
    "for afolder in glob.glob(\"./outputs/testbed/SEP/NOMOTION/*\"):\n",
    "    pairname=afolder.split(\"/\")[-1]\n",
    "    print(afolder)\n",
    "    for efolder in glob.glob(\"{}/*\".format(afolder)):\n",
    "        epsnumber=efolder.split(\"/\")[-1]\n",
    "        print(efolder)\n",
    "        tpevents=np.load(\"{}/positive/true/events.npy\".format(efolder))\n",
    "        tpfeatures=np.load(\"{}/positive/true/features.npy\".format(efolder))\n",
    "        tpparameters=np.load(\"{}/positive/true/parameters.npy\".format(efolder))\n",
    "        tpscores=np.load(\"{}/positive/true/scores.npy\".format(efolder))\n",
    "        \n",
    "        if tpevents.shape[0]==0:\n",
    "            continue\n",
    "        \n",
    "        for order in range(tpevents.shape[0]):\n",
    "            # true_events=np.array([item for item in tpevents[order] if item[1]=='true'])\n",
    "\n",
    "            target=tpevents[order]\n",
    "\n",
    "            min_timestamp=min([float(event[2]) for event in target])\n",
    "            sensor_timestamp={item:[] for item in set(target[:,0])}\n",
    "            for event in target:\n",
    "                sensor_timestamp[event[0]].append(float(event[2])-min_timestamp)\n",
    "\n",
    "            plt.title(\"True-Positive-{}\".format(order))\n",
    "            plt.xlabel(\"timestamp\")\n",
    "            yintv=0.01\n",
    "            for k, v in sensor_timestamp.items():\n",
    "                plt.plot(v, [yintv for _ in range(len(v))], 'o', label=k)\n",
    "                for time_ in v:\n",
    "                    plt.axvline(x=time_, linestyle=\":\")\n",
    "                yintv+=0.01\n",
    "            plt.legend()\n",
    "            plt.savefig(\"./analysis/{}/{}/positive/true/NOMOTION/{}_{}_{}.png\".format(data_name, metric, pairname, epsnumber, order))\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# False Positive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name='testbed'\n",
    "metric='SEP'\n",
    "\n",
    "for afolder in glob.glob(\"./outputs/testbed/SEP/NOMOTION/*\"):\n",
    "    pairname=afolder.split(\"/\")[-1]\n",
    "    print(afolder)\n",
    "    for efolder in glob.glob(\"{}/*\".format(afolder)):\n",
    "        epsnumber=efolder.split(\"/\")[-1]\n",
    "        print(efolder)\n",
    "        tpevents=np.load(\"{}/positive/false/events.npy\".format(efolder))\n",
    "        tpfeatures=np.load(\"{}/positive/false/features.npy\".format(efolder))\n",
    "        tpparameters=np.load(\"{}/positive/false/parameters.npy\".format(efolder))\n",
    "        tpscores=np.load(\"{}/positive/false/scores.npy\".format(efolder))\n",
    "        \n",
    "        if tpevents.shape[0]==0:\n",
    "            continue\n",
    "        \n",
    "        for order in range(tpevents.shape[0]):\n",
    "            # true_events=np.array([item for item in tpevents[order] if item[1]=='true'])\n",
    "\n",
    "            target=tpevents[order]\n",
    "\n",
    "            min_timestamp=min([float(event[2]) for event in target])\n",
    "            sensor_timestamp={item:[] for item in set(target[:,0])}\n",
    "            for event in target:\n",
    "                sensor_timestamp[event[0]].append(float(event[2])-min_timestamp)\n",
    "\n",
    "            plt.title(\"False-Positive-{}\".format(order))\n",
    "            plt.xlabel(\"timestamp\")\n",
    "            yintv=0.01\n",
    "            for k, v in sensor_timestamp.items():\n",
    "                plt.plot(v, [yintv for _ in range(len(v))], 'o', label=k)\n",
    "                for time_ in v:\n",
    "                    plt.axvline(x=time_, linestyle=\":\")\n",
    "                yintv+=0.01\n",
    "            plt.legend()\n",
    "            plt.savefig(\"./analysis/{}/{}/positive/false/NOMOTION/{}_{}_{}.png\".format(data_name, metric, pairname, epsnumber, order))\n",
    "            plt.clf()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
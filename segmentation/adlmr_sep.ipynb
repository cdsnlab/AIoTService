{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import packages\n",
    "\"\"\"\n",
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, random\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "import path, sys, re, time\n",
    "from collections import Counter\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import custom modules\n",
    "\"\"\"\n",
    "from module_.info.config import config\n",
    "from module_.text2array import text2array_adlmr as ttaa\n",
    "from module_.win2feat import sliding_window\n",
    "from module_.cpd import change_point_detection as cpd\n",
    "from module_.evaluation import evaluation_adlmr as ea\n",
    "from module_.analysis import neighbor_events as ne"
   ]
  },
  {
   "source": [
    "# adlmr (CASAS, 2-resident, episodes)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# load data by episode: mixed, group, single\n",
    "# \"\"\"\n",
    "# raw_episodes, single_episodes={}, {}\n",
    "\n",
    "# with open(\"dataset/adlmr/annotated\", 'rb') as f: \n",
    "#     text=f.readlines()\n",
    "#     _, group_stream, _, _, _=ttaa(text)\n",
    "#     group_episodes={idx:item for idx, item in enumerate(group_stream)}\n",
    "\n",
    "# for i in range(1, 27):\n",
    "#     name=str(i) if len(str(i))!=1 else '0'+str(i)\n",
    "#     with open(\"dataset/adlmr/P{}.txt\".format(name), 'rb') as f: \n",
    "#         text=f.readlines()\n",
    "#     single_stream, _, raw_stream, t_single, t_raw=ttaa(text) # NEXT: set transition points\n",
    "#     raw_episodes['P'+name]={'stream':raw_stream, 'transition':t_raw}\n",
    "#     single_episodes['P'+name]={'stream':single_stream, 'transition': t_single}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9042 126\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "# with open(\"dataset/adlmr/annotated\", 'rb') as f:\n",
    "#     text=f.readlines()\n",
    "#     _, _, raw_stream, _, t_raw=ttaa(text)\n",
    "\n",
    "# sensor_list=sorted(set(np.array(raw_stream)[:,0]))\n",
    "# windows=sliding_window(np.array(raw_stream))\n",
    "\n",
    "\"\"\"\n",
    "load single stream\n",
    "\"\"\"\n",
    "\n",
    "dir_=\"preprocessed/adlmr/group/data.pickle\"\n",
    "with open(dir_,'rb') as f:\n",
    "    data=pickle.load(f)\n",
    "\n",
    "\"\"\"\n",
    "raw stream\n",
    "\"\"\"\n",
    "\n",
    "# total=[]\n",
    "# total_atd=[]\n",
    "\n",
    "# for _, df in data.items():\n",
    "#     total+=df['stream']\n",
    "\n",
    "# activity={'1':'1', '2':'2'}\n",
    "# for idx, event in enumerate(total):\n",
    "#     if event[3]!='0':\n",
    "#         if activity[event[3]]!=event[4]: # different activity\n",
    "#             total_atd.append(idx)\n",
    "#             activity[event[3]]=event[4]\n",
    "    \n",
    "#     if event[5]!='0':\n",
    "#         if activity[event[5]]!=event[6]: # different activity\n",
    "#             total_atd.append(idx)\n",
    "#             activity[event[5]]=event[6]\n",
    "# len(total_atd)\n",
    "\n",
    "\"\"\"\n",
    "group stream\n",
    "\"\"\"\n",
    "\n",
    "group=[]\n",
    "group_atd=[]\n",
    "for _, df in data.items():\n",
    "    group_atd.append(len(group)+len(df))\n",
    "    group+=df\n",
    "group_atd=group_atd[:-1]\n",
    "print(len(group), len(group_atd))\n",
    "\"\"\"\n",
    "single stream\n",
    "\"\"\"\n",
    "\n",
    "# one, two=[], []\n",
    "# for _, df in data.items():\n",
    "#     one+=df['stream']['1']\n",
    "#     two+=df['stream']['2']\n",
    "\n",
    "# print(len(one), len(two))\n",
    "\n",
    "# one_atd, two_atd=[],[]\n",
    "# activity={'1':'1', '2':'2'}\n",
    "# for idx, event in enumerate(one):\n",
    "#     if event[3]!='0':\n",
    "#         if event[3]=='1':\n",
    "#             if activity['1']!=event[4]:\n",
    "#                 one_atd.append(idx)\n",
    "#                 activity['1']=event[4]\n",
    "#     if event[5]!='0':\n",
    "#         if event[5]=='1':\n",
    "#             if activity['1']!=event[6]:\n",
    "#                 one_atd.append(idx)\n",
    "#                 activity['1']=event[6]\n",
    "\n",
    "# for idx, event in enumerate(two):\n",
    "#     if event[3]!='0':\n",
    "#         if event[3]=='2':\n",
    "#             if activity['2']!=event[4]:\n",
    "#                 two_atd.append(idx)\n",
    "#                 activity['2']=event[4]\n",
    "#     if event[5]!='0':\n",
    "#         if event[5]=='2':\n",
    "#             if activity['2']!=event[6]:\n",
    "#                 two_atd.append(idx)\n",
    "#                 activity['2']=event[6]\n",
    "\n",
    "# print(len(one_atd), len(two_atd))\n",
    "\n",
    "\"\"\"\n",
    "CPD\n",
    "\"\"\"\n",
    "\n",
    "# sensor_list=sorted(set(np.array(group)[:,0]))\n",
    "# windows=sliding_window(np.array(group))\n",
    "# features, scores, params, changes=cpd(windows, sensor_list, data_name='adlmr', message='group')\n",
    "\n",
    "# message='group'\n",
    "# np.save(\"scores/adlmr/f_{}.npy\".format(message), features)\n",
    "# np.save(\"scores/adlmr/s_{}.npy\".format(message), scores)\n",
    "# np.save(\"scores/adlmr/p_{}.npy\".format(message), params)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# for key in episodes.keys():\n",
    "#     print(key)\n",
    "#     eps=np.array(episodes[key])\n",
    "#     # trs_=np.array(trs_dict[key])\n",
    "\n",
    "#     sensor_set=set(eps[:,0])\n",
    "#     windows=sliding_window(eps)\n",
    "#     features, scores, params=cpd(windows, sensor_set, data_name='adlmr')\n",
    "\n",
    "#     dirname=\"scores/adlmr/{}\".format(key)\n",
    "#     if not os.path.isdir(dirname):\n",
    "#         os.mkdir(dirname)\n",
    "#     np.save(\"{}/f.npy\".format(dirname), features)\n",
    "#     np.save(\"{}/s.npy\".format(dirname), scores)\n",
    "#     np.save(\"{}/p.npy\".format(dirname), params)\n",
    "\n",
    "#     print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "293 6906 1725 118\n0.7128953771289538\n0.19986096628432395\n"
     ]
    }
   ],
   "source": [
    "target='group'\n",
    "scores=np.load(\"scores/adlmr/s_{}.npy\".format(target))\n",
    "features=np.load(\"scores/adlmr/f_{}.npy\".format(target))\n",
    "params=np.load(\"scores/adlmr/p_{}.npy\".format(target))\n",
    "\n",
    "\"\"\"\n",
    "candidates\n",
    "\"\"\"\n",
    "events_=group\n",
    "eval_transitions=group_atd\n",
    "\n",
    "threshold=0.3\n",
    "# candidates_all=[idx if eval_scores[idx]>threshold else 0 for idx in range(cut)]\n",
    "candidates_all=[idx for idx in range(len(scores)) if scores[idx]>threshold]\n",
    "peaks, _=find_peaks(scores)\n",
    "# candidates_peak=[idx if idx in peaks and eval_scores[idx]>threshold else 0 for idx in range(cut)]\n",
    "candidates_peak=[idx for idx in range(len(scores)) if idx in peaks and scores[idx]>threshold]\n",
    "len(eval_transitions), len(candidates_all), len(candidates_peak)\n",
    "\n",
    "\"\"\"\n",
    "measurement\n",
    "\"\"\"\n",
    "transitions_time=np.array([float(events_[idx][2]) for idx in eval_transitions])\n",
    "\n",
    "tp, tn, fp, fn=[],[],[],[]\n",
    "\n",
    "cand=candidates_peak\n",
    "\n",
    "for i in range(len(scores)):\n",
    "    if i in cand: # positive\n",
    "        if i in eval_transitions:\n",
    "            tp.append(i)\n",
    "            continue\n",
    "        timestamp_=float(events_[i][2])\n",
    "        if sum(abs(transitions_time-timestamp_)<10)!=0:\n",
    "            tp.append(i)\n",
    "            continue\n",
    "        fp.append(i)\n",
    "    else:\n",
    "        if i in eval_transitions:\n",
    "            fn.append(i)\n",
    "            continue\n",
    "        tn.append(i)\n",
    "tp_, tn_, fp_, fn_=len(tp), len(tn), len(fp), len(fn)\n",
    "print(tp_, tn_, fp_, fn_)\n",
    "print(tp_/(tp_+fn_))\n",
    "print(fp_/(fp_+tn_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  71,  136,  153,  305,  404,  445,  491,  540,  688,  785,  847,\n",
       "        901, 1006, 1181, 1252, 1314, 1344, 1425, 1596, 1670, 1705, 1768,\n",
       "       1851, 2083, 2156, 2206, 2230, 2269, 2390, 2449, 2501, 2541, 2599,\n",
       "       2672, 2740, 2783, 2821, 2900, 3051, 3135, 3195, 3256, 3299, 3344,\n",
       "       3386, 3478, 3648, 3699, 3747, 3792, 3823, 3903, 3965, 4031, 4049,\n",
       "       4108, 4207, 4288, 4317, 4339, 4428, 4496, 4512, 4557, 4586, 4640,\n",
       "       4773, 4845, 4932, 4965, 5016, 5080, 5155, 5189, 5202, 5236, 5375,\n",
       "       5416, 5441, 5486, 5563, 5678, 5754, 5802, 5825, 5869, 6071, 6165,\n",
       "       6198, 6226, 6290, 6440, 6531, 6563, 6621, 6658, 6769, 6834, 6855,\n",
       "       6916, 6990, 7057, 7104, 7191, 7240, 7418, 7477, 7518, 7584, 7635,\n",
       "       7753, 7827, 7882, 7922, 7963, 8096, 8157, 8216, 8238, 8288, 8470,\n",
       "       8554, 8620, 8653, 8744, 8946, 9042])"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "np.array(group_atd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2584\n2554 ['M13', 'ON', 1226879088.529429, '2', '11', '0', '0']\n2555 ['M13', 'OFF', 1226879090.09085, '2', '11', '0', '0']\n2556 ['M13', 'ON', 1226879099.778959, '2', '11', '0', '0']\n2557 ['M14', 'ON', 1226879100.085429, '2', '11', '0', '0']\n2558 ['M14', 'OFF', 1226879101.502269, '2', '11', '0', '0']\n2559 ['M13', 'OFF', 1226879101.827889, '2', '11', '0', '0']\n2560 ['M13', 'ON', 1226879102.72088, '2', '11', '0', '0']\n2561 ['M14', 'ON', 1226879110.68909, '2', '11', '0', '0']\n2562 ['D07', 'CLOSE', 1226879120.50053, '1', '10', '0', '0']\n2563 ['M14', 'OFF', 1226879121.580329, '2', '11', '0', '0']\n2564 ['M13', 'OFF', 1226879123.74757, '2', '11', '0', '0']\n2565 ['M13', 'ON', 1226879124.949419, '2', '11', '0', '0']\n2566 ['M14', 'ON', 1226879125.523689, '2', '11', '0', '0']\n2567 ['M13', 'OFF', 1226879127.96898, '2', '11', '0', '0']\n2568 ['M14', 'OFF', 1226879129.21844, '2', '11', '0', '0']\n2569 ['M14', 'ON', 1226879130.75899, '2', '11', '0', '0']\n2570 ['M14', 'OFF', 1226879132.34024, '2', '11', '0', '0']\n2571 ['M17', 'ON', 1226879135.15664, '1', '10', '0', '0']\n2572 ['M13', 'ON', 1226879138.934489, '2', '11', '0', '0']\n2573 ['M17', 'OFF', 1226879139.58236, '1', '10', '0', '0']\n2574 ['M17', 'ON', 1226879140.619149, '1', '10', '0', '0']\n2575 ['M13', 'OFF', 1226879141.839709, '2', '11', '0', '0']\n2576 ['M13', 'ON', 1226879144.79324, '2', '11', '0', '0']\n2577 ['M17', 'OFF', 1226879145.117019, '1', '10', '0', '0']\n2578 ['M14', 'ON', 1226879145.438689, '2', '11', '0', '0']\n2579 ['M17', 'ON', 1226879146.83557, '1', '10', '0', '0']\n2580 ['M13', 'OFF', 1226879148.14206, '2', '11', '0', '0']\n2581 ['M14', 'OFF', 1226879148.928849, '2', '11', '0', '0']\n2582 ['M17', 'OFF', 1226879149.25166, '1', '10', '0', '0']\n2583 ['M16', 'ON', 1226879149.5799, '1', '10', '0', '0']\n2584 ['M15', 'ON', 1226879150.03863, '1', '10', '0', '0']\n2585 ['M15', 'OFF', 1226879151.197619, '1', '10', '0', '0']\n0.5309037575812238\n{'etl-D07': 0.121, 'coe-M13': 0.067, 'coe-M15': 0.067, 'etl-M13': 0.036, 'alc': 0.033, 'etl-M14': 0.033, 'etl-M17': 0.032, 'etl-M16': 0.031, 'ls': 0.029, 'lsl': 0.014, 'spm': 0.0, 'wd': 0.0}\n0.4630000000000001\n"
     ]
    }
   ],
   "source": [
    "from module_.helper.labeling import feature_label as fl\n",
    "from module_.info.config import feature_name as fn\n",
    "\n",
    "sensor_list=sorted(set(np.array(events_)[:,0]))\n",
    "# print(features.shape)\n",
    "# idx=candidates_peak[3]\n",
    "# idx=group_atd[32]; print(idx)\n",
    "idx=2584; print(idx)\n",
    "\n",
    "# print(idx, events_[idx])\n",
    "for i in range(32):\n",
    "    idx_=max(0, idx-30+i)\n",
    "    print(idx-30+i, events_[idx_])\n",
    "views=np.array(features[idx])\n",
    "# cols=[]\n",
    "cols_=[]\n",
    "for cnum in range(views.shape[1]):\n",
    "    col=views[:,cnum]\n",
    "    if max(col)!=min(col):\n",
    "        # cols.append(cnum)\n",
    "        cols_.append(np.array(col).reshape((-1,1)))\n",
    "# print(cols, len(cols))\n",
    "feature=np.concatenate(cols_, axis=1)\n",
    "# print(views)\n",
    "cf=fl(np.array(views), sensor_list, fn)\n",
    "\n",
    "fd={}\n",
    "for i, v in enumerate(cf.values()):\n",
    "    # print(v)\n",
    "    f=feature[:,i]\n",
    "    fd[v]=np.round(abs(f[0]-f[-1]), 3)\n",
    "print(scores[idx])\n",
    "sort_fd={k: v for k, v in sorted(fd.items(), key=lambda item: item[1], reverse=True)}\n",
    "print(sort_fd)\n",
    "print(sum(sort_fd.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'episodes' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a58697fda180>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepisodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0meps_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"scores/adlmr\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mf_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}/f.npy\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ms_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}/s.npy\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'episodes' is not defined"
     ]
    }
   ],
   "source": [
    "# for key in episodes.keys():\n",
    "#     eps_dir=\"scores/adlmr\"\n",
    "#     eps=np.array(episodes[key])\n",
    "#     f_=np.load(\"{}/{}/f.npy\".format(eps_dir, key))\n",
    "#     s_=np.load(\"{}/{}/s.npy\".format(eps_dir, key))\n",
    "#     p_=np.load(\"{}/{}/p.npy\".format(eps_dir, key))\n",
    "#     t_=np.load(\"{}/{}/t.npy\".format(eps_dir, key))\n",
    "\n",
    "#     fp, fn, tp, tn = ea(scores, eps, t_)\n",
    "#     tpr, fpr=len(tp)/(len(tp)+len(fn)), len(fp)/(len(fp)+len(tn)) \n",
    "#     print(\"[{}] FP: {} FN: {} TP: {} TN: {}, TPR: {}, FPR: {}\".format(key, len(fp), len(fn), len(tp), len(tn), tpr, fpr))\n",
    "#     print(t_, len(t_))\n",
    "\n",
    "#     # target_=fp\n",
    "#     target_=fp\n",
    "#     f__=f_[np.array(target_)]; s__=s_[np.array(target_)]; p__=p_[np.array(target_)]\n",
    "#     v__=[(item[:2], item[2:]) for item in f__]\n",
    "#     dist_x__=np.array([np.square(distance_matrix(item[0], item[0])) for _, item in enumerate(v__)])\n",
    "#     dist_y__=np.array([np.square(distance_matrix(item[0], item[1])) for _, item in enumerate(v__)])\n",
    "#     phi_x__=np.array([np.exp(-0.5*np.square(distance_matrix(item[0], item[0])) / (p__[k,0]**2)) for k, item in enumerate(v__)])\n",
    "#     phi_y__=np.array([np.exp(-0.5*np.square(distance_matrix(item[0], item[1])) / (p__[k,0]**2)) for k, item in enumerate(v__)])\n",
    "#     weight__=np.array([np.mean(item, axis=0)/p__[k,1] for k, item in enumerate(phi_y__)])\n",
    "#     scores__=np.array([max(0, 1-np.dot(phi_x__[k], item).sum(axis=0)/2) for k, item in enumerate(weight__)])\n",
    "    \n",
    "#     j=40\n",
    "    \n",
    "#     print('{}/{}'.format(j, len(target_)))\n",
    "#     print('target_\\t', target_[j])\n",
    "#     event_seg=ne(eps, target_[j])\n",
    "#     sensor_=set(np.array(event_seg)[:,0])\n",
    "#     print(sensor_, len(sensor_))\n",
    "    \n",
    "#     for k, item in enumerate(event_seg):\n",
    "#         print(max(0, target_[j]-30+k),\"\\t\", item, '*' if k==30 else \"\")\n",
    "\n",
    "#     for k, item in enumerate(f__[j]):\n",
    "#         print(np.round(item,2),'t', k-1)\n",
    "#     print('(sigma, lambda_)', p__[j], scores__[j])\n",
    "#     print(dist_x__[j], 'squared distance (x and x)')\n",
    "#     print(dist_y__[j], 'squared distance (x and y)')\n",
    "#     print('*'*30)\n",
    "#     print(np.round(phi_x__[j],2))\n",
    "#     print(np.round(phi_y__[j],2))\n",
    "#     print(np.round(scores__[j],2))\n",
    "#     print('-'*30)\n",
    "\n",
    "#     break"
   ]
  }
 ]
}